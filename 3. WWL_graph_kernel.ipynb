{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMY5bMZ4bebyDpFC3z/SenC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"BIFp7Wy4Qg6G"},"outputs":[],"source":["!pip install rdkit-pypi\n","!pip install igraph\n","!pip install descriptastorus\n","!pip install networkx\n","!pip install POT\n","!pip install cython numpy"]},{"cell_type":"code","source":["import os\n","import csv\n","import codecs\n","import numpy as np\n","import networkx as nx\n","import pickle\n","import torch\n","\n","from rdkit import Chem\n","from typing import List, Tuple, Union\n","from torch_geometric.utils import from_networkx, tree_decomposition"],"metadata":{"id":"-uOcJ--bckce"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3.1 Construction of igraph objects for WWL graph kernels"],"metadata":{"id":"xWV6YVN6nl0_"}},{"cell_type":"code","source":["#logic: https://www.blopig.com/blog/2022/02/how-to-turn-a-smiles-string-into-a-molecular-graph-for-pytorch-geometric/\n","#Ref: https://github.com/divelab/MoleculeX/blob/molx/AdvProp/graph/src/tran_data.py\n","#atom and bond feature is the same as DMPNN: https://github.com/chemprop/chemprop/blob/02a6f76b21fec9fab000c47d8a185a8c19fecbcb/chemprop/features/featurization.py#L642\n","#lack of following feature\n","#a2b: A mapping from an atom index to a list of incoming bond indices.\n","#b2a: A mapping from a bond index to the index of the atom the bond originates from.\n","#b2revb: A mapping from a bond index to the index of the reverse bond.\n","#b2br: A mapping from f_bonds to real bonds in molecule recorded in targets.\n","\n","import igraph as ig\n","\n","BOND_FDIM = 14\n","\n","MAX_ATOMIC_NUM = 100\n","ATOM_FEATURES = {\n","    'atomic_num': list(range(MAX_ATOMIC_NUM)),\n","    'degree': [0, 1, 2, 3, 4, 5],\n","    'formal_charge': [-1, -2, 1, 2, 0],\n","    'chiral_tag': [0, 1, 2, 3],\n","    'num_Hs': [0, 1, 2, 3, 4],\n","    'hybridization': [\n","        Chem.rdchem.HybridizationType.SP,\n","        Chem.rdchem.HybridizationType.SP2,\n","        Chem.rdchem.HybridizationType.SP3,\n","        Chem.rdchem.HybridizationType.SP3D,\n","        Chem.rdchem.HybridizationType.SP3D2\n","    ],\n","}\n","\n","# Distance feature sizes\n","PATH_DISTANCE_BINS = list(range(10))\n","THREE_D_DISTANCE_MAX = 20\n","THREE_D_DISTANCE_STEP = 1\n","THREE_D_DISTANCE_BINS = list(range(0, THREE_D_DISTANCE_MAX + 1, THREE_D_DISTANCE_STEP))\n","\n","\n","def onek_encoding_unk(value: int, choices: List[int]) -> List[int]:\n","  \"\"\"\n","  Creates a one-hot encoding.\n","  :param value: The value for which the encoding should be one.\n","  :param choices: A list of possible values.\n","  :return: A one-hot encoding of the value in a list of length len(choices) + 1.\n","  If value is not in the list of choices, then the final element in the encoding is 1.\n","  \"\"\"\n","  encoding = [0] * (len(choices) + 1)\n","  index = choices.index(value) if value in choices else -1\n","  encoding[index] = 1\n","\n","  return encoding\n","\n","\n","def atom_features(atom: Chem.rdchem.Atom, functional_groups: List[int] = None) -> List[Union[bool, int, float]]:\n","  \"\"\"\n","  Builds a feature vector for an atom.\n","  :param atom: An RDKit atom.\n","  :param functional_groups: A k-hot vector indicating the functional groups the atom belongs to.\n","  :return: A list containing the atom features.\n","  \"\"\"\n","  features = onek_encoding_unk(atom.GetAtomicNum() - 1, ATOM_FEATURES['atomic_num']) + \\\n","              onek_encoding_unk(atom.GetTotalDegree(), ATOM_FEATURES['degree']) + \\\n","              onek_encoding_unk(atom.GetFormalCharge(), ATOM_FEATURES['formal_charge']) + \\\n","              onek_encoding_unk(int(atom.GetChiralTag()), ATOM_FEATURES['chiral_tag']) + \\\n","              onek_encoding_unk(int(atom.GetTotalNumHs()), ATOM_FEATURES['num_Hs']) + \\\n","              onek_encoding_unk(int(atom.GetHybridization()), ATOM_FEATURES['hybridization']) + \\\n","              [1 if atom.GetIsAromatic() else 0] + \\\n","              [atom.GetMass() * 0.01]  # scaled to about the same range as other features\n","\n","  if functional_groups is not None:\n","      features += functional_groups\n","  return features\n","\n","\n","def bond_features(bond: Chem.rdchem.Bond) -> List[Union[bool, int, float]]:\n","  \"\"\"\n","  Builds a feature vector for a bond.\n","  :param bond: A RDKit bond.\n","  :return: A list containing the bond features.\n","  \"\"\"\n","  if bond is None:\n","      fbond = [1] + [0] * (BOND_FDIM - 1)\n","  else:\n","      bt = bond.GetBondType()\n","      fbond = [\n","          0,  # bond is not None\n","          bt == Chem.rdchem.BondType.SINGLE,\n","          bt == Chem.rdchem.BondType.DOUBLE,\n","          bt == Chem.rdchem.BondType.TRIPLE,\n","          bt == Chem.rdchem.BondType.AROMATIC,\n","          (bond.GetIsConjugated() if bt is not None else 0),\n","          (bond.IsInRing() if bt is not None else 0)\n","      ]\n","      fbond += onek_encoding_unk(int(bond.GetStereo()), list(range(6)))\n","\n","\n","  return fbond\n","\n","def smile_to_graph(smile):\n","  mol = Chem.MolFromSmiles(smile)\n","  atoms = [atom_features(atom) for atom in mol.GetAtoms()] # collecting all node features\n","  atom_n= [atom.GetAtomicNum() for atom in mol.GetAtoms()]\n","  G = nx.Graph()\n","  G2 = nx.Graph()\n","\n","  for i in range(len(atoms)):\n","    G.add_node(i)        # initialize a graph with adding nodes\n","    G.nodes[i]['x'] = atoms[i] # assign node feature\n","    G2.add_node(i)\n","    G2.nodes[i]['label'] = atoms[i]\n","\n","  for i in range(len(atoms)):\n","    for j in range(i, len(atoms)):\n","      bond = mol.GetBondBetweenAtoms(i, j) # initialize edges to previous graph\n","      if bond:\n","        # G is a networkx grpah objects for keeping all D-MPNN model features\n","        G.add_edge(i, j) # adding edges to previous graph\n","        G.edges[i, j]['edge_attr'] = bond_features(bond) # assign bond feature\n","        idx= bond.GetIdx()\n","        # G2 is an igraph objects for WWL graph kernels, the WWL kernels didn't considered bond feature due to the limitation of WWL test\n","        # See https://github.com/BorgwardtLab/WWL/blob/master/src/wwl/wwl.py for detail\n","        G2.add_edge(i, j)\n","        # .NumBondRings(bond.GetIdx()): returns the number of rings that given input: bond idx, is involved in\n","        # In this study, number of rings (N3/N7 ring mentioned in my thesis) is a potenial feature to affect HLM stabilibty, but WWL graph kernels not yet implement\n","        # GetRingInfo(): https://www.rdkit.org/docs/cppapi/classRDKit_1_1RingInfo.html\n","        # NumBondRings: https://www.rdkit.org/docs/cppapi/classRDKit_1_1RingInfo.html#a72f74c9fac23b98e59b64ab27173ff05\n","        # minBondRingSize: https://www.rdkit.org/docs/cppapi/classRDKit_1_1RingInfo.html#a7a85cc1ab6ea186b3a65435b6037a644\n","        G2.edges[i, j]['weight'] = bond.GetOwningMol().GetRingInfo().NumBondRings(bond.GetIdx())\n","\n","  IG_g = ig.Graph.from_networkx(G2)\n","\n","  return G, IG_g"],"metadata":{"id":"GF7I6b_Yc8-3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3.2 Converting SMILES dataset to igraph objects"],"metadata":{"id":"0QC_Qp68n3t5"}},{"cell_type":"code","source":["#Ref: https://github.com/divelab/MoleculeX/blob/molx/AdvProp/graph/src/tran_data.py\n","\n","# get input(smiles) and labels from yuor dataset\n","def data_reader(file_name):\n","\n","  inputs = []\n","  labels = []\n","\n","  with codecs.open(file_name, \"r\", encoding=\"utf-8-sig\") as f:\n","    reader = csv.DictReader(f)\n","    for row in reader:\n","      smiles = row['smiles']\n","      inputs.append(smiles)\n","      labels.append([float(row[y]) if row[y] != '' else np.nan for y in row.keys() if y != 'smiles' and y != 'id'])\n","\n","    return inputs, np.array(labels)\n","\n","\n","smiles, labels = data_reader('/content/eli_duplcate_hf.csv') # get input(smiles) and labels from yuor dataset\n","\n","networks_all=[]\n","igrapg_list_all=[]\n","\n","for smile in smiles:\n","  G, I_G = smile_to_graph(smile)\n","  networks_all.append(G)\n","  igrapg_list_all.append(I_G)\n"],"metadata":{"id":"LIYjLQLmjn6U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir gml\n","#save igraphs in gml files for WWL graph kernel inputs\n","for i in range(len(igrapg_list_all)):\n","  igrapg_list_all[i].write(f'/content/gml/{i}.gml', format='gml')"],"metadata":{"id":"L8lPPCrgmif5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3.3.1 Utility functions of WWL graph kernels"],"metadata":{"id":"EzMJV8hGyYj8"}},{"cell_type":"code","source":["# Ref: https://github.com/BorgwardtLab/WWL/blob/master/experiments/utilities.py\n","\n","import numpy as np\n","import os\n","import igraph as ig\n","\n","#################\n","# File loaders\n","#################\n","def read_labels(filename):\n","  '''\n","  Reads labels from a file. Labels are supposed to be stored in each\n","  line of the file. No further pre-processing will be performed.\n","  '''\n","  labels = []\n","  with open(filename) as f:\n","      labels = f.readlines()\n","      labels = [label.strip() for label in labels]\n","\n","  return labels\n","\n","def read_gml(filename):\n","\tnode_features = []\n","\tg = ig.read(filename)\n","\n","\tif not 'label' in g.vs.attribute_names():\n","\t\tg.vs['label'] = list(map(str, [l for l in g.vs.degree()]))\n","\n","\tnode_features = g.vs['label']\n","\tadj_mat = np.asarray(g.get_adjacency().data)\n","\n","\treturn node_features, adj_mat\n","\n","def retrieve_graph_filenames(data_directory):\n","  # Load graphs\n","  files = os.listdir(data_directory)\n","  graphs = [g for g in files if g.endswith('gml')]\n","  graphs.sort()\n","\n","  return [os.path.join(data_directory, g) for g in graphs]\n","\n","def load_continuous_graphs(data_directory):\n","  graph_filenames = retrieve_graph_filenames(data_directory)\n","\n","  # initialize\n","  node_features = []\n","  adj_mat = []\n","  n_nodes = []\n","\n","  # Iterate across graphs and load initial node features\n","  for graph_fname in graph_filenames:\n","    node_features_cur, adj_mat_cur = read_gml(graph_fname)\n","    # Load features\n","    node_features.append(np.asarray(node_features_cur).astype(float).reshape(-1,1))\n","    adj_mat.append(adj_mat_cur.astype(int))\n","    n_nodes.append(adj_mat_cur.shape[0])\n","\n","  # Check if there is a node_features.npy file\n","  # containing continuous attributes\n","  # PS: these were obtained by processing the TU Dortmund website\n","  # If none is present, keep degree or label as features.\n","  attribtues_filenames = os.path.join(data_directory, 'node_features.npy')\n","  if os.path.isfile(attribtues_filenames):\n","    node_features = np.load(attribtues_filenames)\n","\n","  n_nodes = np.asarray(n_nodes)\n","  node_features = np.asarray(node_features)\n","\n","  return node_features, adj_mat, n_nodes\n","\n","def create_adj_avg(adj_cur):\n","\t'''\n","\tcreate adjacency\n","\t'''\n","\tdeg = np.sum(adj_cur, axis = 1)\n","\tdeg = np.asarray(deg).reshape(-1)\n","\n","\tdeg[deg!=1] -= 1\n","\n","\tdeg = 1/deg\n","\tdeg_mat = np.diag(deg)\n","\tadj_cur = adj_cur.dot(deg_mat.T).T\n","\n","\treturn adj_cur\n","\n","\n","def create_labels_seq_cont(node_features, adj_mat, h):\n","\t'''\n","\tcreate label sequence for continuously attributed graphs\n","\t'''\n","\tn_graphs = len(node_features)\n","\tlabels_sequence = []\n","\tfor i in range(n_graphs):\n","    graph_feat = []\n","\n","\t\tfor it in range(h+1):\n","\t\t\tif it == 0:\n","\t\t\t\tgraph_feat.append(node_features[i])\n","\t\t\telse:\n","\t\t\t\tadj_cur = adj_mat[i] + np.identity(adj_mat[i].shape[0])\n","\t\t\t\tadj_cur = create_adj_avg(adj_cur)\n","\n","\t\t\t\tnp.fill_diagonal(adj_cur, 0)\n","\t\t\t\tgraph_feat_cur = 0.5*(np.dot(adj_cur, graph_feat[it-1]) + graph_feat[it-1])\n","\t\t\t\tgraph_feat.append(graph_feat_cur)\n","\n","\t\tlabels_sequence.append(np.concatenate(graph_feat, axis = 1))\n","\t\tif i % 100 == 0:\n","\t\t\tprint(f'Processed {i} graphs out of {n_graphs}')\n","\n","\treturn labels_sequence"],"metadata":{"id":"fPrlXILqsPwv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3.3.2 Main functions of WWL kernel graphs"],"metadata":{"id":"xubsS9IoyElp"}},{"cell_type":"code","source":["# Ref: https://github.com/BorgwardtLab/WWL/blob/master/experiments/wwl.py\n","\n","import numpy as np\n","from sklearn.preprocessing import scale\n","from sklearn.base import TransformerMixin\n","import argparse\n","import igraph as ig\n","import os\n","import ot\n","\n","####################\n","# Embedding schemes\n","####################\n","def compute_wl_embeddings_continuous(data_directory, h):\n","  '''\n","  Continuous graph embeddings\n","  TODO: for package implement a class with same API as for WL\n","  '''\n","  node_features, adj_mat, n_nodes = load_continuous_graphs(data_directory)\n","\n","  node_features_data = scale(np.concatenate(node_features, axis=0), axis = 0)\n","  splits_idx = np.cumsum(n_nodes).astype(int)\n","  node_features_split = np.vsplit(node_features_data,splits_idx)\n","  node_features = node_features_split[:-1]\n","\n","  # Generate the label sequences for h iterations\n","  labels_sequence = create_labels_seq_cont(node_features, adj_mat, h)\n","\n","  return labels_sequence\n","\n","def compute_wasserstein_distance(label_sequences, h, sinkhorn=False, discrete=False, sinkhorn_lambda=1e-2):\n","  '''\n","  Generate the Wasserstein distance matrix for the graphs embedded\n","  in label_sequences\n","  '''\n","  # Get the iteration number from the embedding file\n","  n = len(label_sequences)\n","  emb_size = label_sequences[0].shape[1]\n","  n_feat = int(emb_size/(h+1))\n","\n","  # Iterate over all possible h to generate the Wasserstein matrices\n","  hs = range(0, h + 1)\n","  wasserstein_distances = []\n","\n","  for h in hs:\n","    M = np.zeros((n,n))\n","    # Iterate over pairs of graphs\n","    for graph_index_1, graph_1 in enumerate(label_sequences):\n","      # Only keep the embeddings for the first h iterations\n","      labels_1 = label_sequences[graph_index_1][:,:n_feat*(h+1)]\n","      for graph_index_2, graph_2 in enumerate(label_sequences[graph_index_1:]):\n","        labels_2 = label_sequences[graph_index_2 + graph_index_1][:,:n_feat*(h+1)]\n","        # Get cost matrix\n","        ground_distance = 'hamming' if discrete else 'euclidean'\n","        costs = ot.dist(labels_1, labels_2, metric=ground_distance)\n","\n","        if sinkhorn:\n","            mat = ot.sinkhorn(np.ones(len(labels_1))/len(labels_1),\n","                                np.ones(len(labels_2))/len(labels_2), costs, sinkhorn_lambda,\n","                                numItermax=50)\n","            M[graph_index_1, graph_index_2 + graph_index_1] = np.sum(np.multiply(mat, costs))\n","        else:\n","            M[graph_index_1, graph_index_2 + graph_index_1] = \\\n","                ot.emd2([], [], costs)\n","\n","    M = (M + M.T)\n","    wasserstein_distances.append(M)\n","    print(f'Iteration {h}: done.')\n","\n","  return wasserstein_distances"],"metadata":{"id":"LqyNKIj3ulwn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import argparse\n","import os\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","\n","h=10\n","label_sequences = compute_wl_embeddings_continuous('content/gml', h)\n","out_name = f'wl_continue_embeddings_{h}.npy'\n","\n","output_path='/content/wwl_embedding'\n","np.save(os.path.join(output_path, out_name), label_sequences)\n","\n","\n","print('Computing the Wasserstein distances...')\n","wasserstein_distances = compute_wasserstein_distance(label_sequences, h, sinkhorn= False, discrete= False)\n","\n","!mkdir Wasserstein_distances\n","output_path2= '/content/Wasserstein_distances'\n","filext = 'wasserstein_distance_matrix'\n","\n","for i, D_w in enumerate(wasserstein_distances):\n","  filext += f'_it_{i}.npy'\n","  np.save(os.path.join(output_path2,filext), D_w)\n","\n","print('Wasserstein distances computation done. Saved to file.')"],"metadata":{"id":"p3ADio72zESr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!zip -r /content/WWL_d.zip /content/Wasserstein_distances"],"metadata":{"id":"360--rdFBWq-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3.4 Evaluating results of WWL graph kernels"],"metadata":{"id":"BBYLFRpLyrSF"}},{"cell_type":"code","source":["from sklearn.model_selection import ParameterGrid, StratifiedKFold\n","from sklearn.model_selection._validation import _fit_and_score\n","from sklearn.base import clone\n","from sklearn.metrics import make_scorer, accuracy_score\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import KFold\n","\n","def custom_grid_search_cv2(model, param_grid, precomputed_kernels, y, cv=5):\n","  '''\n","  Custom grid search based on the sklearn grid search for an array of precomputed kernels\n","  '''\n","  # 1. Stratified K-fold\n","  cv = KFold(n_splits=cv, shuffle=False)\n","  results = []\n","\n","  for train_index, test_index in cv.split(precomputed_kernels[0], y):\n","    split_results = []\n","    params = [] # list of dict, its the same for every split\n","    # run over the kernels first\n","    for K_idx, K in enumerate(precomputed_kernels):\n","      # Run over parameters\n","      for p in list(ParameterGrid(param_grid)):\n","        sc = _fit_and_score(clone(model), K, y, scorer=make_scorer(mean_squared_error,squared= False, greater_is_better= False),\n","                train=train_index, test=test_index, verbose=0, parameters=p, fit_params=None)\n","        split_results.append(sc['test_scores'])\n","        #print(sorted(sc.keys()))\n","        params.append({'K_idx': K_idx, 'params': p})\n","    results.append(split_results)\n","  # Collect results and average\n","  results = np.array(results)\n","  fin_results = results.mean(axis=0)\n","  # select the best results\n","  best_idx = np.argmin(fin_results)\n","  # Return the fitted model and the best_parameters\n","  ret_model = clone(model).set_params(**params[best_idx]['params'])\n","\n","  return ret_model.fit(precomputed_kernels[params[best_idx]['K_idx']], y), params[best_idx]"],"metadata":{"id":"hZOuQwaPCEeM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Ref: https://github.com/BorgwardtLab/WWL/blob/master/experiments/main.py\n","\n","from sklearn.metrics import mean_squared_error\n","from sklearn.svm import SVR\n","\n","gammas = np.logspace(-4,1,num=6)\n","# iterate over the iterations too\n","hs = range(h)\n","param_grid = [\n","    {'C': np.logspace(-3,3,num=7)}\n","        ]\n","\n","kernel_matrices = []\n","kernel_params = []\n","\n","for i, current_h in enumerate(hs):\n","  # Generate the full list of kernel matrices from which to select\n","  M = wasserstein_distances[current_h]\n","  for g in gammas:\n","    K = np.exp(-g*M)\n","    kernel_matrices.append(K)\n","    kernel_params.append((current_h, g))\n","\n","\n","crossvalidation= True\n","print(f'Running SVMs, crossvalidation: {crossvalidation}, gridsearch: {gridsearch}.')\n","# Load labels\n","#label_file = os.path.join(data_path, 'Labels.txt')\n","y = np.array(read_labels('/content/HF.txt'), dtype= np.float16)\n","\n","# Contains accuracy scores for each cross validation step; the\n","# means of this list will be used later on.\n","rmse_scores = []\n","np.random.seed(42)\n","\n","cv = KFold(n_splits=5, shuffle=True)\n","\n","# Hyperparam logging\n","best_C = []\n","best_h = []\n","best_gamma = []\n","finm=[]\n","\n","for i in range(len(kernel_matrices)):\n","  meanv=[]\n","  for train_index, test_index in cv.split(kernel_matrices[i], y):\n","    K_train = [K[train_index][:, train_index] for K in kernel_matrices]\n","    K_test  = [K[test_index][:, train_index] for K in kernel_matrices]\n","    y_train, y_test = y[train_index], y[test_index]\n","\n","    # Gridsearch\n","    if gridsearch:\n","        gs, best_params = custom_grid_search_cv2(SVR(kernel='precomputed'),\n","                param_grid, K_train, y_train, cv=5)\n","        # Store best params\n","        C_ = best_params['params']['C']\n","        h_, gamma_ = kernel_params[best_params['K_idx']]\n","        y_pred = gs.predict(K_test[best_params['K_idx']])\n","        #print(y_pred)\n","    elif gridsearch== False:\n","        gs = SVR(C=100, kernel='precomputed').fit(K_train[0], y_train)\n","        y_pred = gs.predict(K_test[0])\n","        h_, gamma_, C_ = h, gammas[0], 100\n","    best_C.append(C_)\n","    best_h.append(h_)\n","    best_gamma.append(gamma_)\n","\n","    rmse_scores.append(mean_squared_error(y_test, y_pred, squared=False))\n","    if not crossvalidation:\n","      break\n","    meanv.append(mean_squared_error(y_test, y_pred, squared=False))\n","\n","  finm.append(np.mean(meanv))\n","\n","print(finm)"],"metadata":{"id":"lPJUcPIkDtUg"},"execution_count":null,"outputs":[]}]}