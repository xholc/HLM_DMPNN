{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["Nxly-WkqGtHN"],"authorship_tag":"ABX9TyM9DpjhlJ1eL3NlXt4DfpNx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Install packages"],"metadata":{"id":"A8avMyR1Dquq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ZygryaHDgYw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706760242494,"user_tz":-480,"elapsed":143858,"user":{"displayName":"鍾岳辰","userId":"02693086127626364792"}},"outputId":"d33bf04d-d267-4189-ba40-b4209774a2c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting hdbscan\n","  Downloading hdbscan-0.8.33.tar.gz (5.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting cython<3,>=0.27 (from hdbscan)\n","  Using cached Cython-0.29.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from hdbscan) (1.23.5)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan) (1.11.4)\n","Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.10/dist-packages (from hdbscan) (1.2.2)\n","Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->hdbscan) (3.2.0)\n","Building wheels for collected packages: hdbscan\n","  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hdbscan: filename=hdbscan-0.8.33-cp310-cp310-linux_x86_64.whl size=3039285 sha256=e97f7db2e46b416a0d0a5e826b42e1ca0fd0ff29923a94c5d7db73fa56464461\n","  Stored in directory: /root/.cache/pip/wheels/75/0b/3b/dc4f60b7cc455efaefb62883a7483e76f09d06ca81cf87d610\n","Successfully built hdbscan\n","Installing collected packages: cython, hdbscan\n","  Attempting uninstall: cython\n","    Found existing installation: Cython 3.0.8\n","    Uninstalling Cython-3.0.8:\n","      Successfully uninstalled Cython-3.0.8\n","Successfully installed cython-0.29.37 hdbscan-0.8.33\n","Collecting kmedoids\n","  Downloading kmedoids-0.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (468 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.8/468.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: kmedoids\n","Successfully installed kmedoids-0.5.0\n","Collecting rdkit-pypi\n","  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (1.23.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (9.4.0)\n","Installing collected packages: rdkit-pypi\n","Successfully installed rdkit-pypi-2022.9.5\n","Requirement already satisfied: yellowbrick in /usr/local/lib/python3.10/dist-packages (1.5)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from yellowbrick) (3.7.1)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from yellowbrick) (1.11.4)\n","Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from yellowbrick) (1.2.2)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from yellowbrick) (1.23.5)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from yellowbrick) (0.12.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.2.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (4.47.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.8.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->yellowbrick) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->yellowbrick) (3.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.16.0)\n","Collecting ipyplot\n","  Downloading ipyplot-1.1.2-py3-none-any.whl (13 kB)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (from ipyplot) (7.34.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ipyplot) (1.23.5)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from ipyplot) (9.4.0)\n","Collecting shortuuid (from ipyplot)\n","  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython->ipyplot) (67.7.2)\n","Collecting jedi>=0.16 (from IPython->ipyplot)\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython->ipyplot) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython->ipyplot) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython->ipyplot) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython->ipyplot) (3.0.43)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython->ipyplot) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython->ipyplot) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython->ipyplot) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython->ipyplot) (4.9.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython->ipyplot) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython->ipyplot) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->ipyplot) (0.2.13)\n","Installing collected packages: shortuuid, jedi, ipyplot\n","Successfully installed ipyplot-1.1.2 jedi-0.19.1 shortuuid-1.0.11\n"]}],"source":["!pip install hdbscan\n","!pip install kmedoids\n","!pip install rdkit-pypi\n","!pip install yellowbrick\n","!pip install ipyplot"]},{"cell_type":"markdown","source":["# 4.1 Loading wwl distance matrix"],"metadata":{"id":"1Hb883GFXb44"}},{"cell_type":"code","source":["import numpy as np\n","# Here is the best iteration I selelcted\n","wwl_d_6 = np.load('/content/wasserstein_distance_matrix_it6.npy')"],"metadata":{"id":"Wpy3rTi3Fd0h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4.2 seed selection of tsne (for projection)"],"metadata":{"id":"58WRrCEvuqm9"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.manifold import TSNE\n","X= wwl_d_6\n","seed= np.arange(1, 50)\n","log=[]\n","for i in seed:\n","  test = TSNE(n_iter=500, metric='precomputed', init='random', random_state=i).fit(X)\n","  log.append(test.kl_divergence_)\n","best= np.argmax(np.array(log))\n","\n","print('best KL div: {result}'.format(result= log[best]))\n","print('best_seed: {seed}'.format(seed= seed[best]))"],"metadata":{"id":"m5HX3tzLulk_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4.3 Kmeans"],"metadata":{"id":"j3VSVJIID7Yj"}},{"cell_type":"code","source":["#Ref: https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html\n","\n","from sklearn.datasets import make_blobs\n","from sklearn.manifold import TSNE\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_samples, silhouette_score\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","import numpy as np\n","\n","\n","X= wwl_d_6\n","projection = TSNE(metric='precomputed', init='random',  random_state=8).fit_transform(X)\n","range_n_clusters= list(int(i) for i in range(10,51))\n","\n","for n_clusters in range_n_clusters:\n","  # Create a subplot with 1 row and 2 columns\n","  fig, (ax1, ax2) = plt.subplots(1, 2)\n","  fig.set_size_inches(18, 7)\n","\n","  # The 1st subplot is the silhouette plot\n","  # The silhouette coefficient can range from -1, 1 but in this example all\n","  # lie within [-0.1, 1]\n","  ax1.set_xlim([-0.1, 1])\n","  # The (n_clusters+1)*10 is for inserting blank space between silhouette\n","  # plots of individual clusters, to demarcate them clearly.\n","  ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n","\n","  # Initialize the clusterer with n_clusters value and a random generator\n","  # seed of 10 for reproducibility.\n","  clusterer = KMeans(n_clusters=n_clusters, n_init=1, random_state=13)\n","  cluster_labels = clusterer.fit_predict(X)\n","\n","  # The silhouette_score gives the average value for all the samples.\n","  # This gives a perspective into the density and separation of the formed\n","  # clusters\n","  silhouette_avg = silhouette_score(X, cluster_labels)\n","  print(\n","      \"For n_clusters =\",\n","      n_clusters,\n","      \"The average silhouette_score is :\",\n","      silhouette_avg,\n","  )\n","\n","  # Compute the silhouette scores for each sample\n","  sample_silhouette_values = silhouette_samples(X, cluster_labels)\n","\n","  y_lower = 10\n","  for i in range(n_clusters):\n","    # Aggregate the silhouette scores for samples belonging to\n","    # cluster i, and sort them\n","    ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n","    ith_cluster_silhouette_values.sort()\n","    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n","    y_upper = y_lower + size_cluster_i\n","\n","    color = cm.nipy_spectral(float(i) / n_clusters)\n","    ax1.fill_betweenx(\n","        np.arange(y_lower, y_upper),\n","        0,\n","        ith_cluster_silhouette_values,\n","        facecolor=color,\n","        edgecolor=color,\n","        alpha=0.7,\n","    )\n","\n","    # Label the silhouette plots with their cluster numbers at the middle\n","    ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n","    # Compute the new y_lower for next plot\n","    y_lower = y_upper + 10  # 10 for the 0 samples\n","\n","  ax1.set_title(\"The silhouette plot for the various clusters.\")\n","  ax1.set_xlabel(\"The silhouette coefficient values\")\n","  ax1.set_ylabel(\"Cluster label\")\n","\n","  # The vertical line for average silhouette score of all the values\n","  ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n","  ax1.set_yticks([])  # Clear the yaxis labels / ticks\n","  ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n","\n","  # 2nd Plot showing the actual clusters formed\n","  colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n","  ax2.scatter(\n","      *projection.T, marker=\".\", s=30, lw=0, alpha=0.7, c=colors, edgecolor=\"k\"\n","  )\n","  ax2.set_title(\"The TSNE visualization of the clustered data.\")\n","  ax2.set_xlabel(\"Feature space for the 1st feature\")\n","  ax2.set_ylabel(\"Feature space for the 2nd feature\")\n","\n","  plt.suptitle(\n","      \"Silhouette analysis for KMeans clustering on sample data with n_clusters = %d\"\n","      % n_clusters,\n","      fontsize=14,\n","      fontweight=\"bold\",\n","  )\n","\n","plt.show()"],"metadata":{"id":"9ZoXjg7DD9Br"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.cluster import KMeans\n","from yellowbrick.cluster import KElbowVisualizer\n","\n","# Instantiate the clustering model and visualizer\n","X=wwl_d_6\n","model = KMeans(n_init=1, random_state=13)\n","# Ref: https://www.scikit-yb.org/en/latest/api/cluster/elbow.html#yellowbrick.cluster.elbow.KElbowVisualizer\n","# The K-Elbow Visualizer implements the “elbow” method of selecting the optimal number of clusters for K-means clustering.\n","# If the line chart looks like an arm, then the “elbow” (the point of inflection on the curve) is the best value of k.\n","visualizer = KElbowVisualizer(model, k=(10,51))\n","\n","visualizer.fit(X)\n","visualizer.show()"],"metadata":{"id":"EWsyQrw5FFXr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.cluster import KMeans\n","\n","df= pd.read_csv('/content/eli_duplcate_hf.csv')\n","smiles, target= df['smiles'], df['half_life']\n","kmeans= KMeans(n_clusters=26, n_init=1, random_state=13).fit(X)\n","kmean_df= pd.DataFrame()\n","kmean_df['smiles'], kmean_df['half_life'], kmean_df['cluster_label']= smiles, target, kmeans.labels_\n","kmean_df.to_csv('kmean_df.csv', index=False)\n","\n","cluster_ids, cluster_sizes = np.unique(kmeans.labels_, return_counts=True)\n","print(cluster_sizes)\n","print(cluster_ids)"],"metadata":{"id":"mfzVCRqbFnYN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4.4 HDBSCAN"],"metadata":{"id":"MFisR8VtGR7l"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from hdbscan import hdbscan, HDBSCAN\n","from hdbscan.flat import HDBSCAN_flat, approximate_predict_flat, membership_vector_flat, all_points_membership_vectors_flat\n","from sklearn.manifold import TSNE\n","from mpl_toolkits.axisartist.axislines import Subplot\n","%matplotlib inline\n","\n","X= wwl_d_6\n","projection= TSNE(n_iter=500, metric='precomputed', init='random', random_state=8).fit_transform(X)\n","sc=np.arange(6, 50, 1)\n","\n","for c in sc:\n","  #The primary parameter to effect the resulting clustering is min_cluster_size. Ideally this is a relatively intuitive parameter to select\n","  #set it to the smallest size grouping that you wish to consider a cluster.\n","  clusterer = HDBSCAN(metric=\"precomputed\", cluster_selection_method=\"eom\", min_cluster_size=c).fit(X)\n","  labels = clusterer.labels_\n","  cluster_ids, cluster_sizes = np.unique(labels, return_counts=True)\n","  print(f\"Number of elements assigned to each cluster in {c}: {cluster_sizes}\")\n","  proba = clusterer.probabilities_\n","  # A score of how persistent each cluster is. Using this parameter to select best min_cluster_size\n","  #A score of 1.0 represents a perfectly stable cluster that persists over all distance scales, while a score of 0.0 represents a perfectly ephemeral cluster.\n","  print(clusterer.cluster_persistence_)\n","  fig, ax = plt.subplots()\n","\n","  fig.suptitle('TSNE plot of HDBSCAN clustering result', fontweight =\"bold\")\n","\n","  plt.scatter(project[labels>=0, 0], project[labels>=0, 1], c=labels[labels>=0], s=5, cmap=plt.cm.jet)\n","  plt.scatter(project[labels<0, 0], project[labels<0, 1], c='k', s=3, marker='x', alpha=0.2)\n","  print(f\"Unique labels (-1 for outliers): {np.unique(labels)}\")\n","\n","  ax.set_xlabel(\"Feature space for the 1st feature\")\n","  ax.set_ylabel(\"Feature space for the 2nd feature\")\n","  plt.show()"],"metadata":{"id":"AIJNJzjPGHbP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","df= pd.read_csv('/content/eli_duplcate_hf.csv')\n","smiles, target= df['smiles'], df['half_life']\n","clusterer = HDBSCAN(metric=\"precomputed\", cluster_selection_method=\"eom\", min_cluster_size=10).fit(X)\n","hdbscan_df= pd.DataFrame()\n","hdbscan_df['smiles'], hdbscan_df['half_life'], hdbscan_df['cluster_label']= smiles, target, clusterer.labels_\n","hdbscan_df.to_csv('hdbscandf.csv', index=False)\n","\n","cluster_ids, cluster_sizes = np.unique(clusterer.labels_, return_counts=True)\n","print(cluster_sizes)\n","print(cluster_ids)"],"metadata":{"id":"KlKkLXQeHgIg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.manifold import TSNE\n","wwl_d_6 = np.load('/content/wasserstein_distance_matrix_it6.npy')\n","X= wwl_d_6\n","projection= TSNE(n_components=2, n_iter=500, metric='precomputed', init='random', random_state=8).fit_transform(X)\n","\n","df= pd.read_csv('/content/hdbscandf.csv')\n","labels = df['cluster_label']\n","cluster_ids, cluster_sizes = np.unique(labels, return_counts=True)\n","df2 = pd.DataFrame()\n","df2[\"y\"] = labels\n","df2[\"Feature space for the 1st feature\"] = projection[:,0]\n","df2[\"Feature space for the 2nd feature\"] = projection[:,1]\n","fig, ax = plt.subplots()\n","fig.set_size_inches(9, 7)\n","sns.scatterplot(x=\"Feature space for the 1st feature\", y=\"Feature space for the 2nd feature\", hue=df2.y.tolist(),\n","                palette= sns.color_palette(\"hls\", len(cluster_ids)),\n","                data= df2).set(title=\"TSNE plot of HDBSCAN clustering result\")"],"metadata":{"id":"fiNUdXN4sdZq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4.5 Kmedoids"],"metadata":{"id":"BgbrVv6oHy3D"}},{"cell_type":"code","source":["import kmedoids\n","from sklearn.preprocessing import MinMaxScaler\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","X=wwl_d_6\n","c= np.arange(10, 51, 1, dtype=int)\n","algo=['fasterpam', 'fastermsc', 'fastpam1']\n","seed=[103, 109, 135]\n","\n","for a, s in zip(algo, seed):\n","  kk_lb=[]\n","  kk_ind=[]\n","  kk_iner=[]\n","  kk_ms=[]\n","\n","  for i in c:\n","    #print(i)\n","    kk= kmedoids.KMedoids(n_clusters= int(i), metric='precomputed', metric_params=None, method=a, init='random', max_iter=300, random_state=int(s))\n","    k6= kk.fit(wwl_d_6)\n","    k6p= kk.fit_predict(wwl_d_6)\n","    kk_lb.append(k6p)\n","    kk_ind.append(k6.medoid_indices_)\n","    km_ms = kmedoids.medoid_silhouette(X, k6.medoid_indices_)\n","    #print(km_ms[0])\n","    kk_ms.append(km_ms[0])\n","    #print(k6.inertia_)\n","    kk_iner.append(k6.inertia_)\n","\n","  # The clusters in optimal k are assumed to have the smallest inertia; conversely, the Medoid Silhouette should be as near to 1 as possible.\n","  # we plot average score curve(inertia and medoid_silhouette) first, and the best k should be the point of inflection on the average score curve,\n","  x1 = list(c)\n","  y1 = kk_ms\n","  plt.plot(x1, y1, color='red', linestyle=\"-\", linewidth=\"2\", markersize=\"16\", marker=\".\", label=\"medoid_silhouette_score\")\n","  # MinMaxScale for better visualization\n","  scler= MinMaxScaler()\n","  kch= np.array(kk_iner).reshape(-1, 1)\n","  y2 = scler.fit_transform(kch)\n","  plt.plot(x1, y2, color='blue', linestyle=\"-\", linewidth=\"2\", markersize=\"16\", marker=\".\", label=\"minMaxscale_kmedoids_inertia\")\n","  plt.xlim(10, 50)\n","  plt.ylim(np.min(y2)-0.25, np.max(y2)+0.25)\n","\n","  plt.xlabel('cluster_n', fontsize=\"10\")\n","  plt.ylabel('value', fontsize=\"10\")\n","  plt.title(f'Kmedoids_{a} clustering', fontsize=\"18\")\n","\n","  plt.legend()\n","  plt.show()"],"metadata":{"id":"xhjPwx_WH03n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import kmedoids\n","X=wwl_d_6\n","df= pd.read_csv('/content/eli_duplcate_hf.csv')\n","smiles, target= df['smiles'], df['half_life']\n","km_m = kmedoids.KMedoids(17, metric='precomputed', method='fastermsc', init='random', random_state=109)\n","km_m.fit(X)\n","fastermsc= pd.DataFrame()\n","fastermsc['smiles'], fastermsc['half_life'], fastermsc['cluster_label']= smiles, target, km_m.labels_\n","fastermsc.to_csv('fastermsc.csv', index=False)\n","\n","cluster_ids, cluster_sizes = np.unique(km_m.labels_, return_counts=True)\n","print(cluster_sizes)\n","print(cluster_ids)"],"metadata":{"id":"FSWBL6-RI9F1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.manifold import TSNE\n","wwl_d_6 = np.load('/content/wasserstein_distance_matrix_it6.npy')\n","X= wwl_d_6\n","projection= TSNE(n_components=2, n_iter=500, metric='precomputed', init='random', random_state=8).fit_transform(X)\n","df= pd.read_csv('/content/fastermsc.csv')\n","\n","labels = df['cluster_label']\n","cluster_ids, cluster_sizes = np.unique(labels, return_counts=True)\n","df2 = pd.DataFrame()\n","df2[\"y\"] = labels\n","df2[\"Feature space for the 1st feature\"] = projection[:,0]\n","df2[\"Feature space for the 2nd feature\"] = projection[:,1]\n","fig, ax = plt.subplots()\n","fig.set_size_inches(9, 7)\n","sns.scatterplot(x=\"Feature space for the 1st feature\", y=\"Feature space for the 2nd feature\", hue=df2.y.tolist(),\n","                palette= sns.color_palette(\"hls\", len(cluster_ids)),\n","                data= df2).set(title=\"TSNE plot of FasterMSC clustering result\")"],"metadata":{"id":"IB0Z4iDIIotb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4.6 Plot structures"],"metadata":{"id":"RZKC_kAsGWmt"}},{"cell_type":"code","source":["import pandas as pd\n","\n","kmean_df= pd.read_csv('/content/kmean_df.csv')"],"metadata":{"id":"NcfzSwvH0_Qc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from rdkit import Chem\n","from rdkit.Chem import Draw\n","from rdkit.Chem import rdFMCS\n","from PIL import Image\n","from typing import List, Tuple, Union\n","%matplotlib inline\n","\n","# Here is an example of kmeans for demonstration, these clusters are minor classes tempted to be potenial outliers\n","kcluster_12= kmean_df[kmean_df['cluster_label'] == 12]\n","kcluster_13= kmean_df[kmean_df['cluster_label'] == 13]\n","kcluster_18= kmean_df[kmean_df['cluster_label'] == 18]\n","kcluster_23= kmean_df[kmean_df['cluster_label'] == 23]\n","kcluster_24= kmean_df[kmean_df['cluster_label'] == 24]\n","\n","mol12 = [Chem.MolFromSmiles(i) for i in kcluster_12['smiles']]\n","mol13 = [Chem.MolFromSmiles(i) for i in kcluster_13['smiles']]\n","mol18 = [Chem.MolFromSmiles(i) for i in kcluster_18['smiles']]\n","mol23 = [Chem.MolFromSmiles(i) for i in kcluster_23['smiles']]\n","mol24 = [Chem.MolFromSmiles(i) for i in kcluster_24['smiles']]\n","\n","\n","k_mols = [mol12, mol13, mol18, mol23, mol24]\n","\n","\n","def find_save_mcs(smiles, filename):\n","  k_m=[]\n","  for i in smiles:\n","    # find MCS of each group\n","    mcs1 = rdFMCS.FindMCS(i)\n","    print(f\"MCS1 contains {mcs1.numAtoms} atoms and {mcs1.numBonds} bonds.\")\n","    print(\"MCS SMARTS string:\", mcs1.smartsString)\n","    m1 = Chem.MolFromSmarts(mcs1.smartsString)\n","    k_m.append(m1)\n","    img= Draw.MolToImage(m1, legend=\"MCS1\")\n","  k_img = Draw.MolsToGridImage(k_m)\n","  png = k_img.data\n","  with open(f'{filename}.png','wb+') as outf:\n","    outf.write(png)\n","\n","  return k_m\n","\n","\n","\n","k_m= find_save_mcs(k_mols, 'kmeans_mcs')\n","#open the MCS image just saved\n","Image.open('/content/kmeans_mcs.png')"],"metadata":{"id":"sK9OhEXIF_ra","colab":{"base_uri":"https://localhost:8080/","height":599},"executionInfo":{"status":"ok","timestamp":1706761244618,"user_tz":-480,"elapsed":8,"user":{"displayName":"鍾岳辰","userId":"02693086127626364792"}},"outputId":"caa8f9b4-08bd-42a3-a884-25a06f0346c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MCS1 contains 7 atoms and 6 bonds.\n","MCS SMARTS string: [#7]-,:[#6]:,-[#6]:,-[#6]:,-[#6]:,-[#6]:,-[#6]\n","MCS1 contains 10 atoms and 9 bonds.\n","MCS SMARTS string: [#6](-,:[#7]-,:[#6]:,-[#6]:,-[#6])-,:[#6]-,:[#6]-,:[#6]:,-[#6]:,-[#6]\n","MCS1 contains 8 atoms and 7 bonds.\n","MCS SMARTS string: [#6]:,-[#7]:,-[#6]:,-[#6]:,-[#6]:,-[#6]:,-[#6]:,-[#6]\n","MCS1 contains 6 atoms and 5 bonds.\n","MCS SMARTS string: [#6](:,-[#6]:,-[#6]:,-[#6]):,-[#6]:,-[#6]\n","MCS1 contains 5 atoms and 4 bonds.\n","MCS SMARTS string: [#6](-,:[#7]-,:[#6]-,:[#6]):,-[#6]\n"]},{"output_type":"execute_result","data":{"text/plain":["<PIL.PngImagePlugin.PngImageFile image mode=RGB size=600x400>"],"image/png":"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\n"},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["from rdkit import rdBase, Chem\n","from rdkit.Chem import AllChem, Draw\n","from rdkit.Chem.Scaffolds import MurckoScaffold\n","from rdkit.Chem import rdFMCS\n","from matplotlib.colors import ColorConverter\n","import ipyplot\n","\n","highlightColor= ColorConverter().to_rgb('turquoise')\n","\n","def plot_mcs_on_compounds(smiles, mcs)\n","  for mol, mcs in zip(smiles, mcs):\n","    imglist=[]\n","    for i in mol:\n","      img= Draw.MolToImage(i, highlightAtoms=i.GetSubstructMatch(mcs), highlightBonds=i.GetSubstructMatch(mcs), highlightColor=highlightColor)\n","      imglist.append(img)\n","    ipyplot.plot_images(imglist, img_width=150)\n","\n","plot_mcs_on_compounds(k_mols, k_m)"],"metadata":{"id":"qLraN-MwGGEk","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1s3MPNCpNBO6cXKNAVYv6rK5d0hVYVJ8p"},"executionInfo":{"status":"ok","timestamp":1706761255106,"user_tz":-480,"elapsed":4884,"user":{"displayName":"鍾岳辰","userId":"02693086127626364792"}},"outputId":"0fcee075-955d-46b2-eff6-d00dbf789bb6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["# 4.7 Plot MDS plot"],"metadata":{"id":"Nxly-WkqGtHN"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.manifold import MDS\n","\n","wwl= np.load('/content/wasserstein_distance_matrix_it6.npy')\n","seed=[]\n","sel=[]\n","for i in np.random.randint(1, 10000, size=300):\n","  np.random.seed(i)\n","  mds_test = MDS(n_components=2, n_jobs=-1, random_state=i, dissimilarity='precomputed')\n","  candidate = mds_test.fit(wwl)\n","  seed.append(i)\n","  sel.append(candidate.stress_)\n","\n","ind= np.argmin(sel)\n","print(seed[ind])"],"metadata":{"id":"4P4wMhMiGvAN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.manifold import MDS\n","import matplotlib.pyplot as plt\n","\n","def plot_MDS(distance_matrix, HL_file, CL_file):\n","\n","  wwl= np.load(f'{distance_matrix}')\n","  df1= pd.read_csv(f'{HL_file}')\n","  smiles= df1['SMILES']\n","  hf= df1['STANDARD_VALUE']\n","  sb= df1['TYPE']\n","  LT= {'unstable':0, 'moderate':1, 'stable':2}\n","  sbl= [ LT[i] for i in sb ]\n","\n","  dic1_df1= dict(zip(smiles,hf))\n","  dic2_df1= dict(zip(smiles,sbl))\n","\n","  df2= pd.read_csv(f'{CL_file}')\n","  smi= df2['smiles']\n","  cl= df2['cluster_label']\n","  dic3_df2= dict(zip(smi,cl))\n","\n","  group_labels = []\n","  stability_labels = []\n","  half_life_values = []\n","\n","  for i in smi:\n","    group_labels.append(dic3_df2[i])\n","    stability_labels.append(dic2_df1[i])\n","    half_life_values.append(dic1_df1[i])\n","\n","\n","  group_labels= np.array(group_labels)\n","  stability_labels= np.array(stability_labels)\n","  half_life_values= np.array(half_life_values)\n","\n","  data = {'Group': group_labels, 'Stability': stability_labels, 'Half-Life': half_life_values}\n","  metadata = pd.DataFrame(data)\n","\n","  # Apply MDS to the distance matrix\n","  mds = MDS(n_components=2, n_jobs=-1, random_state=8264, dissimilarity='precomputed')\n","  coordinates = mds.fit_transform(wwl)\n","\n","  # Plot the MDS results with color-coded points\n","  plt.figure(figsize=(30, 30))\n","\n","  # Scatter plot for each point in the MDS coordinates\n","  scatter = plt.scatter(coordinates[:, 0], coordinates[:, 1], c=group_labels, cmap= plt.cm.jet, s=100, alpha=0.8)\n","\n","  # Add a colorbar for group labels\n","  plt.colorbar(scatter, label='Group Labels', ticks=np.unique(group_labels))\n","\n","  for i, label in enumerate(group_labels):\n","      plt.annotate(str(label), (coordinates[i, 0], coordinates[i, 1]), fontsize=8, ha='center', va='center')\n","\n","  # Annotate points with stability labels\n","  for i, stab in enumerate(stability_labels):\n","      plt.text(coordinates[i, 0], coordinates[i, 1], f'ST: {stab}', fontsize=8, ha='right', va='bottom')\n","\n","  # Annotate points with half-life values\n","  #for i, hl in enumerate(half_life_values):\n","      #plt.text(coordinates[i, 0], coordinates[i, 1], f'HL: {hl:.2f}', fontsize=8, ha='right', va='bottom')\n","\n","  # Set axis labels and show the plot\n","  plt.xlabel('MDS Dimension 1')\n","  plt.ylabel('MDS Dimension 2')\n","  plt.title('MDS Visualization with Additional Information')\n","  plt.grid(True)\n","  plt.show()"],"metadata":{"id":"uJNjDFDvG6e2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_MDS('/content/wasserstein_distance_matrix_it6.npy', '/content/regression_equal_no_ion_5_smaller.csv', '/content/kmean_df.csv')"],"metadata":{"id":"zl5SHqF7G79M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_MDS('/content/wasserstein_distance_matrix_it6.npy', '/content/regression_equal_no_ion_5_smaller.csv', '/content/hdbscandf.csv')"],"metadata":{"id":"vwkXOq1zHHUF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_MDS('/content/wasserstein_distance_matrix_it6.npy', '/content/regression_equal_no_ion_5_smaller.csv', '/content/fastermsc.csv')"],"metadata":{"id":"Ww-DVDY0HJrO"},"execution_count":null,"outputs":[]}]}