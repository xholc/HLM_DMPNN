{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["JHRSrOQmIAmp","pF21RaUvT1Jy","sKleFc7BPV1u","rsmxpkZ5TvzF","ByVu191gM_wh","ESNx1GX_NtpQ","Sg04zx5YPmBG","OnWRNxSBPtcV","AoUU_AKtm_Qr","-vaFee6qa8Lj","juXjFLikuKT5","ADcFzNTeHrdi","BACrNqtPu5ZH"],"gpuType":"T4","authorship_tag":"ABX9TyMVZgCzbi/DofrQZZsUufUS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Confirm your Torch version(torch 2.1.0+cu121 was validated ok)"],"metadata":{"id":"3DSYwL76HdnM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Omkeoq2fGt5I"},"outputs":[],"source":["import torch\n","torch.__version__"]},{"cell_type":"markdown","source":["# Install package"],"metadata":{"id":"JHRSrOQmIAmp"}},{"cell_type":"code","source":["import os\n","import torch\n","os.environ['TORCH'] = torch.__version__\n","\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","!pip install jedi\n","!pip install --pre dgl -f https://data.dgl.ai/wheels-test/cu121/repo.html\n","!pip install --pre dglgo -f https://data.dgl.ai/wheels-test/repo.html\n","!pip install dgllife\n","!pip install rdkit-pypi\n","!pip install --pre deepchem\n","!pip install optuna\n","!pip install seaborn\n","!pip install cairosvg"],"metadata":{"id":"TdAGJQe9HPKb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706822728370,"user_tz":-480,"elapsed":51770,"user":{"displayName":"鍾岳辰","userId":"02693086127626364792"}},"outputId":"2561015e-ea73-4708-8596-42559c2c2b32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting jedi\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi) (0.8.3)\n","Installing collected packages: jedi\n","Successfully installed jedi-0.19.1\n","Looking in links: https://data.dgl.ai/wheels-test/cu121/repo.html\n","Collecting dgl\n","  Downloading https://data.dgl.ai/wheels-test/cu121/dgl-2.1a240201%2Bcu121-cp310-cp310-manylinux1_x86_64.whl (881.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m881.0/881.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.23.5)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.1)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n","Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (0.7.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.11.17)\n","Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl) (2.1.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (1.12)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchdata>=0.5.0->dgl) (2.1.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchdata>=0.5.0->dgl) (1.3.0)\n","Installing collected packages: dgl\n","Successfully installed dgl-2.1a240201+cu121\n","Looking in links: https://data.dgl.ai/wheels-test/repo.html\n","Collecting dglgo\n","  Downloading dglgo-0.0.2-py3-none-any.whl (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (0.9.0)\n","Collecting isort>=5.10.1 (from dglgo)\n","  Downloading isort-6.0.0b2-py3-none-any.whl (105 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.3/105.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting autopep8>=1.6.0 (from dglgo)\n","  Downloading autopep8-2.0.4-py2.py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting numpydoc>=1.1.0 (from dglgo)\n","  Downloading numpydoc-1.6.0-py3-none-any.whl (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.10.14)\n","Collecting ruamel.yaml>=0.17.20 (from dglgo)\n","  Downloading ruamel.yaml-0.18.5-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from dglgo) (6.0.1)\n","Collecting ogb>=1.3.3 (from dglgo)\n","  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rdkit-pypi (from dglgo)\n","  Downloading rdkit_pypi-2023.3.1b1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.2.2)\n","Collecting pycodestyle>=2.10.0 (from autopep8>=1.6.0->dglgo)\n","  Downloading pycodestyle-2.11.1-py2.py3-none-any.whl (31 kB)\n","Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\n","Requirement already satisfied: sphinx>=5 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (5.0.2)\n","Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (3.1.3)\n","Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (0.9.0)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (2.1.0+cu121)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.23.5)\n","Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (4.66.1)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.5.3)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.16.0)\n","Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (2.0.7)\n","Collecting outdated>=0.2.0 (from ogb>=1.3.3->dglgo)\n","  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.0->dglgo) (4.5.0)\n","Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.20->dglgo)\n","  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (3.2.0)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.4.0->dglgo) (8.1.7)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi->dglgo) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.4)\n","Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (67.7.2)\n","Collecting littleutils (from outdated>=0.2.0->ogb>=1.3.3->dglgo)\n","  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.31.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2023.4)\n","Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.8)\n","Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.6)\n","Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.1)\n","Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.0.5)\n","Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.1.10)\n","Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.7)\n","Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.16.1)\n","Requirement already satisfied: docutils<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (0.18.1)\n","Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.2.0)\n","Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.14.0)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (0.7.16)\n","Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.4.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (23.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.2.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (2.1.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb>=1.3.3->dglgo) (1.3.0)\n","Building wheels for collected packages: littleutils\n","  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7026 sha256=8216d3f08c1a6de98f198a3165cbe715592665cfa08fa36dd685305acf232fcf\n","  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n","Successfully built littleutils\n","Installing collected packages: littleutils, ruamel.yaml.clib, rdkit-pypi, pycodestyle, isort, ruamel.yaml, outdated, autopep8, ogb, numpydoc, dglgo\n","Successfully installed autopep8-2.0.4 dglgo-0.0.2 isort-6.0.0b2 littleutils-0.2.2 numpydoc-1.6.0 ogb-1.3.6 outdated-0.2.2 pycodestyle-2.11.1 rdkit-pypi-2023.3.1b1 ruamel.yaml-0.18.5 ruamel.yaml.clib-0.2.8\n","Collecting dgllife\n","  Downloading dgllife-0.3.2-py3-none-any.whl (226 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.5.3)\n","Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgllife) (4.66.1)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.23.5)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.11.4)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgllife) (3.2.1)\n","Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (from dgllife) (0.2.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.3.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (2023.11.17)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->dgllife) (3.2.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (1.16.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (0.18.3)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (2.2.1)\n","Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (0.10.9.7)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2023.4)\n","Installing collected packages: dgllife\n","Successfully installed dgllife-0.3.2\n","Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.10/dist-packages (2023.3.1b1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (1.23.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (9.4.0)\n","Collecting deepchem\n","  Downloading deepchem-2.7.2.dev20240131192922-py3-none-any.whl (991 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m991.5/991.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.3.2)\n","Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.23.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.5.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.2.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.12)\n","Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.11.4)\n","Collecting rdkit (from deepchem)\n","  Downloading rdkit-2023.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2023.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit->deepchem) (9.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deepchem) (3.2.0)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->deepchem) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->deepchem) (1.16.0)\n","Installing collected packages: rdkit, deepchem\n","Successfully installed deepchem-2.7.2.dev20240131192922 rdkit-2023.9.4\n","Collecting optuna\n","  Downloading optuna-3.5.0-py3-none-any.whl (413 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.4/413.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting colorlog (from optuna)\n","  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.24)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.4)\n","Installing collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.2 alembic-1.13.1 colorlog-6.8.2 optuna-3.5.0\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n","Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.23.5)\n","Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.5.3)\n","Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.47.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2023.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n","Collecting cairosvg\n","  Downloading CairoSVG-2.7.1-py3-none-any.whl (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cairocffi (from cairosvg)\n","  Downloading cairocffi-1.6.1-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.1/75.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cssselect2 (from cairosvg)\n","  Downloading cssselect2-0.7.0-py3-none-any.whl (15 kB)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from cairosvg) (0.7.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from cairosvg) (9.4.0)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from cairosvg) (1.2.1)\n","Requirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from cairocffi->cairosvg) (1.16.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from cssselect2->cairosvg) (0.5.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.1.0->cairocffi->cairosvg) (2.21)\n","Installing collected packages: cssselect2, cairocffi, cairosvg\n","Successfully installed cairocffi-1.6.1 cairosvg-2.7.1 cssselect2-0.7.0\n"]}]},{"cell_type":"code","source":["import deepchem as dc\n","import deepchem.metrics\n","import numpy as np\n","import pandas as pd\n","import os\n","import tempfile\n","import sys\n","from sklearn import metrics\n","import rdkit\n","from rdkit import Chem\n","from rdkit.Chem import Draw\n","from rdkit.Chem.Draw import IPythonConsole\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\", category=UserWarning)\n","np.set_printoptions(threshold=sys.maxsize)"],"metadata":{"id":"15dukKLlIuZC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706822740254,"user_tz":-480,"elapsed":11886,"user":{"displayName":"鍾岳辰","userId":"02693086127626364792"}},"outputId":"cddadb61-152a-4328-ea00-5876ae5e7132"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for SPS. Feature removed!\n","WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for AvgIpc. Feature removed!\n"]},{"output_type":"stream","name":"stdout","text":["Error: Unable to import pysam. Please make sure it is installed.\n","Error: Unable to import pysam. Please make sure it is installed.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n","Instructions for updating:\n","experimental_relax_shapes is deprecated, use reduce_retracing instead\n","DGL backend not selected or invalid.  Assuming PyTorch for now.\n"]},{"output_type":"stream","name":"stdout","text":["Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:deepchem.models:Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n","WARNING:deepchem.models:Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n"]}]},{"cell_type":"markdown","source":["# 1.1 Radom seed selection"],"metadata":{"id":"pF21RaUvT1Jy"}},{"cell_type":"code","source":["import random\n","import torch\n","def set_seed(seed: int = 42) -> None:\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    # When running on the CuDNN backend, two further options must be set\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    # Set a fixed value for the hash seed\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    print(f\"Random seed set as {seed}\")"],"metadata":{"id":"P9w2TjavI0rF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gc\n","import os\n","import torch\n","\n","test= pd.read_csv('/content/eli_duplcate_hf.csv')\n","df2= pd.DataFrame(test)\n","\n","rng = np.random.default_rng()\n","r2 = dc.metrics.Metric(dc.metrics.r2_score, np.mean, mode=\"regression\")\n","test_log=[]\n","test_seed=[]\n","\n","for i in rng.integers(1,10000, size=200):\n","  print(i)\n","  set_seed(i)\n","  # use 10% of datasets to perform seed selection in acceptable training time, you can change this ratio to make a more robust results\n","  test_df = df2.sample(frac=0.1)\n","  test_smiles=list(test_df['smiles'])\n","  test_label=list(test_df['half_life'])\n","  X = dc.feat.DMPNNFeaturizer(features_generators=[\"rdkit_desc_normalized\"]).featurize(test_smiles)\n","  dataset = dc.data.NumpyDataset(X=X, y=test_label)\n","  splitter = dc.splits.splitters.RandomSplitter()\n","  trainset, testset = splitter.train_test_split(dataset, frac_train=0.9, seed=i)\n","  #release memory\n","  gc.collect()\n","  torch.cuda.empty_cache()\n","  #initializing a model should make a independent trial each time, your loss and r2 score should not be very high or improving gradually\n","  model = dc.models.DMPNNModel(mode='regression', depth=6, enc_dropout_p= 0, enc_hidden=1800, ffn_dropout_p= 0, ffn_hidden=1800, ffn_layers= 2, batch_size=50, global_features_size=200, optimizer=opt_adam, device = 'cuda')\n","  # higher epoch more robsut results, but training time not in linear increment. Epoch 30 is my DMPNN model start to enter plateau stage during training\n","  loss =  model.fit(trainset, nb_epoch=30)\n","  print(loss)\n","  train_predictions = model.evaluate(testset, metrics= r2)\n","  train_score = train_predictions['mean-r2_score']\n","  print(train_score)\n","  #The objective function can substitute to other metrics. e.g: MAE, RMSE, R2, accuracy ...etc\n","  test_log.append(train_score)\n","  test_seed.append(i)\n","  # clearing training result in case interfering next trail\n","  gc.collect()\n","  torch.cuda.empty_cache()\n","\n","max_value= max(test_log)\n","print(\"Max value element : \", max_value)\n","index = test_log.index(max_value)\n","select_seed=test_seed[index]\n","print(select_seed)"],"metadata":{"id":"al08NekIT-Oq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1.2 Define datasets of cross-validation and testing"],"metadata":{"id":"sKleFc7BPV1u"}},{"cell_type":"code","source":["select_seed= 1348 # Here is my best random seed\n","\n","DMPNN_featurizer=dc.feat.DMPNNFeaturizer(features_generators=[\"rdkit_desc_normalized\"])\n","# GCN_featurizer = dc.feat.graph_features.ConvMolFeaturizer()\n","\n","set_seed(select_seed)\n","\n","#loader = dc.data.data_loader.CSVLoader(tasks: =>column name of target values , feature_field: =>column name of input smiles, featurizer = DMPNN_featurizer for D-MPNN, GCN_featurizer for GCN)\n","loader = dc.data.data_loader.CSVLoader(tasks=['half_life'] , feature_field = \"smiles\", featurizer = DMPNN_featurizer)\n","# loader = dc.data.data_loader.CSVLoader(tasks=['half_life'] , feature_field = \"smiles\", featurizer = GCN_featurizer)\n","dataset= loader.create_dataset('/content/eli_duplcate_hf.csv')\n","\n","#determine how to split and the train/ test ratio of your datasets\n","splitter = dc.splits.splitters.RandomSplitter()\n","trainset, testset = splitter.train_test_split(dataset, frac_train=0.9, seed=select_seed) # seed: 1348\n","\n","# Create k-fold coss-validation datasets, in k*(train, valid) style\n","fold_datas = splitter.k_fold_split(trainset, k=5)"],"metadata":{"id":"uKrWAfogJfpt","colab":{"base_uri":"https://localhost:8080/","height":256},"executionInfo":{"status":"error","timestamp":1706837445969,"user_tz":-480,"elapsed":18,"user":{"displayName":"鍾岳辰","userId":"02693086127626364792"}},"outputId":"3bbfe5f3-45e7-49d5-bca8-3a8bc7c5bb61"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'dc' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-5b9d476118f9>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mselect_seed\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1348\u001b[0m \u001b[0;31m# Here is my best random seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mDMPNN_featurizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMPNNFeaturizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_generators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rdkit_desc_normalized\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# GCN_featurizer = dc.feat.graph_features.ConvMolFeaturizer()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dc' is not defined"]}]},{"cell_type":"markdown","source":["# 1.3.1 Hyperparameters searching (GCN)"],"metadata":{"id":"rsmxpkZ5TvzF"}},{"cell_type":"code","source":["import optuna\n","r2 = dc.metrics.Metric(dc.metrics.r2_score, np.mean, mode=\"regression\")\n","RMSE = dc.metrics.Metric(dc.metrics.mean_squared_error, np.sqrt, mode=\"regression\")\n","\n","def opt_GCN(trial):\n","\n","  model = dc.models.GraphConvModel(\n","                        n_tasks= 1,\n","                        batch_size= trial.suggest_int('batch_size',16, 512, step=16),\n","                        learning_rate= trial.suggest_float('learning_rate',1e-3, 1e-2,log=True),\n","                        # graph_conv_layers can be [64], [64,64],[64,64,64] .. etc multiple layers but need brackets\n","                        graph_conv_layers= trial.suggest_categorical('graph_conv_layers',[[64,64,64,64],[128,128,128,128],[64,64,64,64,64],[128,128,128,128,128]]),\n","                        dense_layer_size= trial.suggest_int('dense_layer_size', 256, 512, step=2),\n","                        dropouts= trial.suggest_float('dropouts',1e-3, 1e-2, log=True),\n","                        #epoch= trial.suggest_int('batch_size',0, 150, step=10),\n","                        batch_normalize= True,\n","                        mode= 'regression' )\n","\n","\n","\n","\n","  CV_train_score = 0\n","  CV_valid_score = 0\n","\n","  for train_set, val_set in fold_datas:\n","\n","    model.fit(train_set, nb_epoch=100, deterministic=True)\n","    train_predictions = model.evaluate(train_set,[r2])\n","    train_score = train_predictions['mean-r2_score']\n","    CV_train_score += train_score\n","\n","    valid_predictions = model.evaluate(val_set,[r2])\n","    valid_score = valid_predictions['mean-r2_score']\n","    CV_valid_score += valid_score\n","\n","    trial.report(valid_score,step=100)\n","\n","    if trial.should_prune():\n","      print(\"---------------prune----------------\")\n","      raise optuna.TrialPruned()\n","\n","    #print(str(args_dict))\n","  print(CV_train_score/5)\n","  print(CV_valid_score/5)\n","  CV_valid_score= CV_valid_score/5\n","\n","  return 1-CV_valid_score\n","\n","sampler = TPESampler(**TPESampler.hyperopt_parameters())\n","study_gcn = optuna.create_study(direction='minimize', sampler=sampler,\n","               pruner=optuna.pruners.HyperbandPruner(min_resource=10, max_resource=100, reduction_factor= 5)\n","                            )\n","study_gcn.optimize(opt_GCN, n_trials = 100, n_jobs=-1)\n","\n","print('Number of finished trials:', len(study_gcn.trials))\n","print('Best trial parameters:', study_gcn.best_trial.params)\n","print('Best score:', study_gcn.best_value)"],"metadata":{"id":"2IY6I5RdM4j3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_GCN_para= study_gcn.best_trial.params"],"metadata":{"id":"MlQeOzzSN9e7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1.3.2Hyperparameters searching (DMPNN)"],"metadata":{"id":"ByVu191gM_wh"}},{"cell_type":"code","source":["from deepchem.models import DMPNNModel\n","import numpy as np\n","from deepchem.models import optimizers, losses\n","import optuna\n","from optuna.samplers import TPESampler\n","\n","device = 'cuda'\n","r2 = dc.metrics.Metric(dc.metrics.r2_score, np.mean, mode=\"regression\")\n","RMSE = dc.metrics.Metric(dc.metrics.mean_squared_error, np.sqrt, mode=\"regression\")\n","\n","def opt_DMPNN(trial):\n","\n","  model = dc.models.DMPNNModel(\n","                        mode= 'regression',\n","                        n_tasks= 1,\n","                        use_default_fdim= True,\n","                        enc_hidden= trial.suggest_int('enc_hidden', 300, 1800, step=100),\n","                        depth= trial.suggest_int('depth', 6, 10, step=2),\n","                        enc_dropout_p= trial.suggest_float('enc_dropout_p', 0.0001, 0.1, log= True),\n","                        ffn_hidden= trial.suggest_int('ffn_hidden', 300, 1800, step=100),\n","                        ffn_layers= trial.suggest_int('ffn_layers', 2, 10, step= 2),\n","                        ffn_dropout_p= trial.suggest_float('ffn_dropout_p', 0.00001, 0.1, log= True),\n","                        learning_rate= trial.suggest_float('learning_rate',0.00001, 0.1, log=True),\n","                        batch_size= trial.suggest_int('batch_size', 30, 100, step=10),\n","                        global_features_size=200,\n","                        batch_normalize=True,\n","                        opt_adam = optimizers.AdamW(learning_rate= 'learning_rate', weight_decay=trial.suggest_float('weight_decay', 0.00001, 0.1, log= True)),\n","                        device = device\n","                                                                      )\n","\n","\n","  step=40\n","  CV_train_RMSE = 0\n","  CV_valid_RMSE = 0\n","  count=0\n","  for i in range(len(fold_datas)):\n","    opt_t, opt_v= fold_datas[i]\n","    model.fit(opt_t, nb_epoch=step)\n","    train_predictions_RMSE = model.evaluate(opt_t,[RMSE])\n","    train_RMSE= train_predictions_RMSE['sqrt-mean_squared_error']\n","    print('train_loss: ', train_RMSE)\n","    CV_train_RMSE += train_RMSE\n","\n","    valid_predictions_RMSE = model.evaluate(opt_v,[RMSE])\n","    valid_RMSE= valid_predictions_RMSE['sqrt-mean_squared_error']\n","    print('valid_loss: ', valid_RMSE)\n","    CV_valid_RMSE += valid_RMSE\n","\n","    count+=1\n","    if count > 2:\n","      trial.report(valid_RMSE/3,step=step)\n","\n","      if trial.should_prune():\n","        print(\"---------------prune----------------\")\n","        raise optuna.TrialPruned()\n","\n","\n","  print('Trail end, final train loss: ', CV_train_RMSE/5)\n","  print('Trail end, final valid loss: ',CV_valid_RMSE/5)\n","\n","  CV_final_RMSE= CV_valid_RMSE/5\n","  print(CV_final_RMSE)\n","\n","  return CV_final_RMSE\n","\n","sampler = TPESampler(**TPESampler.hyperopt_parameters())\n","study_dmpnn = optuna.create_study(direction='minimize',sampler=sampler,\n","               pruner=optuna.pruners.HyperbandPruner(min_resource=6, max_resource=40, reduction_factor= 5))\n","\n","study_dmpnn.optimize(opt_DMPNN, n_trials = 200, n_jobs=-1)\n","\n","print('Number of finished trials:', len(study_dmpnn.trials))\n","print('Best trial parameters:', study_dmpnn.best_trial.params)\n","print('Best score:', study_dmpnn.best_value)"],"metadata":{"id":"pQJq0Bz1QOya"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_DMPNN_para= study_dmpnn.best_trial.params"],"metadata":{"id":"oX8t2E8XS8jt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1.3.3 Plots of Optuna Trial (DMPNN for an example)"],"metadata":{"id":"ESNx1GX_NtpQ"}},{"cell_type":"code","source":["fig = optuna.visualization.plot_param_importances(study_dmpnn)\n","fig.show()"],"metadata":{"id":"_i08BQ9iS35h","colab":{"base_uri":"https://localhost:8080/","height":201},"executionInfo":{"status":"error","timestamp":1706837500429,"user_tz":-480,"elapsed":469,"user":{"displayName":"鍾岳辰","userId":"02693086127626364792"}},"outputId":"f34ffa7c-398d-40a5-a2a0-563ebd4d0f31"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'optuna' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-d4597a6f0ae6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_param_importances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy_dmpnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'optuna' is not defined"]}]},{"cell_type":"code","source":["fig2= optuna.visualization.plot_edf(study_dmpnn)\n","fig2.show()"],"metadata":{"id":"WH69VjyDS4_x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"error","timestamp":1706837500430,"user_tz":-480,"elapsed":11,"user":{"displayName":"鍾岳辰","userId":"02693086127626364792"}},"outputId":"6ac1d62e-b172-4cf7-eeb7-334d5ac965af"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'optuna' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-86e2281143ef>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_edf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy_dmpnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfig2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'optuna' is not defined"]}]},{"cell_type":"markdown","source":["# 1.4 Define model used in training (GCN or DMPNN, only choosing 1 for training)"],"metadata":{"id":"Sg04zx5YPmBG"}},{"cell_type":"code","source":["# GraphConvModel is a keras based model\n","model_gcn = dc.models.GraphConvModel(\n","                        n_tasks= 1,\n","                        batch_size= best_GCN_para['batch_size'],\n","                        learning_rate= best_GCN_para['learning_rate'],\n","                        graph_conv_layers= best_GCN_para['graph_conv_layers'],\n","                        dense_layer_size= best_GCN_para['dense_layer_size'],\n","                        dropouts= best_GCN_para['dropouts'],\n","                        batch_normalize= True,\n","                        mode= 'regression' )\n"],"metadata":{"id":"BVuMvZplU3PZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from deepchem.models import optimizers, losses\n","\n","set_seed(select_seed)\n","opt_adam = optimizers.AdamW(best_DMPNN_para['learning_rate'], weight_decay=best_DMPNN_para['weight_decay'])\n","\n","# DMPNNModel is a pytorch based model\n","model_dmpnn = dc.models.DMPNNModel(\n","                        mode= 'regression',\n","                        n_tasks= 1,\n","                        enc_hidden= best_DMPNN_para['enc_hidden'],\n","                        depth= best_DMPNN_para['depth'],\n","                        enc_dropout_p= best_DMPNN_para['enc_dropout_p'],\n","                        ffn_hidden= best_DMPNN_para['ffn_hidden'],\n","                        ffn_layers= best_DMPNN_para['ffn_layers'],\n","                        ffn_dropout_p= best_DMPNN_para['ffn_dropout_p'],\n","                        learning_rate= best_DMPNN_para['learning_rate'],\n","                        batch_size= best_DMPNN_para['batch_size'],\n","                        global_features_size=200,\n","                        optimizer=opt_adam,\n","                        device = 'cuda' )"],"metadata":{"id":"jV_brpSJPRjK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1.5 Main function of 5-fold cv training and testing with record"],"metadata":{"id":"OnWRNxSBPtcV"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import deepchem as dc\n","\n","r2 = dc.metrics.Metric(dc.metrics.r2_score, np.mean, mode=\"regression\")\n","RMSE = dc.metrics.Metric(dc.metrics.mean_squared_error, np.sqrt, mode=\"regression\")\n","\n","def main(start_epoch:int, end_epoch:int, fold_datas:deepchem.data.DiskDataset, testset:deepchem.data.DiskDataset, model:deepchem.models, ckpt_dir, best_dir):\n","\n","  train_history3=[]\n","  valid_historty3=[]\n","  train_loss3=[]\n","  valid_loss3=[]\n","  test_history3=[]\n","  test_loss3=[]\n","  train_P=[]\n","  valid_P=[]\n","  test_P=[]\n","  # Threshold of determining best checkpoint by RMSE\n","  best=1\n","\n","  for i in range(start_epoch, end_epoch+1):\n","    CV_train_score = 0\n","    CV_valid_score = 0\n","    CV_train_RMSE = 0\n","    CV_valid_RMSE = 0\n","    test_o_score = 0\n","    test_o_RMSE = 0\n","\n","    for train_set, val_set in fold_datas:\n","\n","      loss = model.fit(train_set, nb_epoch = i)\n","\n","      train_predictions = model.evaluate(train_set, metrics= r2)\n","      train_score = train_predictions['mean-r2_score']\n","      CV_train_score += train_score\n","      valid_predictions = model.evaluate(val_set, metrics= r2)\n","      valid_score = valid_predictions['mean-r2_score']\n","      CV_valid_score += valid_score\n","      test_predictions = model.evaluate(testset, metrics= r2)\n","      test_score = test_predictions['mean-r2_score']\n","      print('test_r2: ', test_score)\n","      test_o_score += test_score\n","      #rmse\n","      train_predictions_RMSE = model.evaluate(train_set,[RMSE])\n","      rse= train_predictions_RMSE['sqrt-mean_squared_error']\n","      train_RMSE = rse\n","      CV_train_RMSE += train_RMSE\n","      valid_predictions_RMSE = model.evaluate(val_set,[RMSE])\n","      rse_val= valid_predictions_RMSE['sqrt-mean_squared_error']\n","      valid_RMSE = rse_val\n","      CV_valid_RMSE += valid_RMSE\n","      test_RMSE = model.evaluate(testset,[RMSE])\n","      res_test = test_RMSE['sqrt-mean_squared_error']\n","      test_RMSE_score = res_test\n","      test_o_RMSE += test_RMSE_score\n","    # collecting performace records\n","    tp= model.predict(train_set)\n","    vp= model.predict(val_set)\n","    tep= model.predict(testset)\n","    train_P.append(tp)\n","    valid_P.append(vp)\n","    test_P.append(tep)\n","    # you can add std error function here for more complete results, before get the mean performance of each epoch\n","    CV_valid_score = CV_valid_score/5\n","    CV_train_score = CV_train_score/5\n","    CV_train_RMSE = CV_train_RMSE/5\n","    CV_valid_RMSE = CV_valid_RMSE/5\n","    test_o_score = test_o_score/5\n","    test_o_RMSE = test_o_RMSE/5\n","\n","    print('--------epoch--------:',i)\n","    print('train_r2: ', CV_train_score)\n","    print('train_loss: ', CV_train_RMSE)\n","    print('valid_r2: ', CV_valid_score)\n","    print('valid_loss: ', CV_valid_RMSE)\n","    print('test_r2: ', test_o_score)\n","    print('test_loss: ', test_o_RMSE)\n","\n","    train_history3.append(CV_train_score)\n","    valid_historty3.append(CV_valid_score)\n","    train_loss3.append(CV_train_RMSE)\n","    valid_loss3.append(CV_valid_RMSE)\n","    test_history3.append(test_o_score)\n","    test_loss3.append(test_o_RMSE)\n","\n","    model.save_checkpoint(model_dir=f'{ckpt_dir}')\n","    #save the checkpoint of best result, you can use model.restore('path to checkpoint') to load a trained model\n","    if test_o_RMSE < best:\n","      model.save_checkpoint(max_checkpoints_to_keep=1, model_dir=f'{best_dir}')\n","      best = test_o_RMSE\n","    train_log= pd.DataFrame.from_dict({'train_r2': np.array(train_history3), 'train_rmse': np.array(train_loss3)})\n","    tpd= np.array(train_P)\n","    # This function can prevent unexpectable termination of your training, you can load this file to plot training curve\n","    np.save('tpd.npy', tpd)\n","    # This function can prevent unexpectable termination of your training,\n","    # you can svae this file to evaluate performance of your most recently trained model\n","    train_log.to_csv('train_log.csv', index=False)\n","    # validation and testing are same as trainimg\n","    valid_log= pd.DataFrame.from_dict({'valid_r2': np.array(valid_historty3), 'valid_rmse': np.array(valid_loss3)})\n","    vpd= np.array(valid_P)\n","    np.save('vpd.npy', vpd)\n","    valid_log.to_csv('valid_log.csv', index=False)\n","    test_log= pd.DataFrame.from_dict({'test_r2': np.array(test_history3), 'test_rmse': np.array(test_loss3)})\n","    tepd= np.array(test_P)\n","    np.save('tepd.npy', tepd)\n","    test_log.to_csv('test_log.csv', index=False)\n","\n","  return train_log, valid_log, test_log, [tpd, vpd, tepd]"],"metadata":{"id":"M6UrqKUQLJRT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Demonstrate DMPNN here\n","\n","!mkdir /content/dmpnn\n","!mkdir /content/dmpnn/ckpt_dir\n","!mkdir /content/dmpnn/best_dir\n","\n","train, valid, test, pred = main(start_epoch=1, end_epoch=50, fold_datas=fold_datas, testset=testset, model=model_dmpnn, ckpt_dir='/content/dmpnn/ckpt_dir', best_dir='/content/dmpnn/best_dir')"],"metadata":{"id":"Gb_rm8tDNlLV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1.6 Save and output results"],"metadata":{"id":"AoUU_AKtm_Qr"}},{"cell_type":"code","source":["def save_table(train_df: pd.DataFrame, valid_df: pd.DataFrame, test_df: pd.DataFrame, predict_arr: np.array, testset:deepchem.data.DiskDataset, out_name:str, out_path:str):\n","  #Objective: r2\n","  ind_M= np.argmax(test_df['test_r2'])\n","  print(ind_M)\n","  print(train_df['train_r2'][ind_M])\n","  print(valid_df['valid_r2'][ind_M])\n","  print(test_df['test_r2'][ind_M])\n","  print('\\n')\n","  print(train_df['train_rmse'][ind_M])\n","  print(valid_df['valid_rmse'][ind_M])\n","  print(test_df['test_rmse'][ind_M])\n","  print('-----------------------------')\n","  #Objective: rmse\n","  ind_M2= np.argmin(test_df['test_rmse'])\n","  print(ind_M2)\n","  print(train_df['train_r2'][ind_M2])\n","  print(valid_df['valid_r2'][ind_M2])\n","  print(test_df['test_r2'][ind_M2])\n","  print('\\n')\n","  print(train_df['train_rmse'][ind_M2])\n","  print(valid_df['valid_rmse'][ind_M2])\n","  print(test_df['test_rmse'][ind_M2])\n","  # Here the rmse reuslts are chosen to output, ypu can change to r2 by substituting ind_M2 to ind_M\n","  # the target values are in hours and taken nature log in original datasets, but we transfom preidcted values to minutes for evalute the real performance\n","  exp_pred_te=np.exp(np.ravel(predict_arr[2][ind_M2]))\n","  te_pred_P= 60*np.array((exp_pred_te))\n","  exp_test_te=np.exp(np.ravel(testset.y))\n","  te_pred_T= 60*np.array(exp_test_te)\n","\n","  #record of prediction results to testset\n","  df_r3=pd.DataFrame()\n","  df_r3['SMILES']=testset.ids\n","  df_r3['Observed(min)']=te_pred_T\n","  df_r3['Prediction of testing-set(min)']=te_pred_P\n","  print(df_r3)\n","  df_r3.to_csv(f\"{out_path}/{out_name}_DMPNN_testing_pred_vs_obsered.csv\", index=False)\n","\n","  df_r3['difference']= np.abs(df_r3['Prediction of testing-set(min)']- df_r3['Observed(min)'])\n","  print(df_r3[df_r3['difference']>60])\n","  drawsmi=df_r3[df_r3['difference']>60]['SMILES']\n","  bigger60= df_r3[df_r3['difference']>60]\n","  # 60 mins is a threshold in this study, if the differencebetwwen observed and prediction bigger than 60 mins then it would be considered as bad prediction;\n","  # smaller than 60 mins are considred acceptable\n","  bigger60.to_csv(f'{out_path}/{out_name}_biggerthan60.csv', index=False)\n","\n","  df_r4=pd.DataFrame()\n","  # training record\n","  df_r4['fold_train_history']=train_df['train_r2']\n","  df_r4['fold_valid_history']=valid_df['valid_r2']\n","  df_r4['fold_test_history']=test_df['test_r2']\n","  df_r4['fold_train_loss']=train_df['train_rmse']\n","  df_r4['fold_valid_loss']=valid_df['valid_rmse']\n","  df_r4['fold_test_loss']=test_df['test_rmse']\n","\n","  df_r4.to_csv(f\"{out_path}/{out_name}_deepchem_record.csv\")"],"metadata":{"id":"asnSI3hbm9dD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# take DMPNN model as example continued here\n","save_table(train, valid, test, pred, testset, out_name='No_dataselection', out_path='/content/dmpnn')"],"metadata":{"id":"80jGIVgwovSf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1.7 Prediction functions"],"metadata":{"id":"-vaFee6qa8Lj"}},{"cell_type":"code","source":["from deepchem.models import optimizers, losses\n","\n","select_seed= 1348\n","set_seed(select_seed)\n","# This model considered as your trained model in previous parts, this seed and model are best hyperparameters combination of my DMPNN model\n","weight_decay = 5 # also known as l2_regularization_lambda\n","learning_rate = 4\n","opt_adam = optimizers.AdamW(learning_rate= 0.0001, weight_decay=0.00001)\n","\n","\n","model_dmpnn = dc.models.DMPNNModel(    mode='regression',\n","                    depth=6,\n","                    enc_dropout_p= 0,\n","                    enc_hidden=1800,\n","                    ffn_dropout_p= 0,\n","                    ffn_hidden=1800,\n","                    ffn_layers= 2,\n","                    batch_size=50,\n","                    global_features_size=200,\n","                    optimizer=opt_adam,\n","                    device = 'cuda'    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LFsr4nPRjaL-","executionInfo":{"status":"ok","timestamp":1706823088144,"user_tz":-480,"elapsed":835,"user":{"displayName":"鍾岳辰","userId":"02693086127626364792"}},"outputId":"4a7b86c9-c088-4e2c-8508-f9831819a540"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Random seed set as 1348\n"]}]},{"cell_type":"code","source":["# read unseen smiles, and converting to graphs\n","import pandas as pd\n","import numpy as np\n","\n","# ***You need to run the training steps first to train a model, then you can load checkpint with model.restore() to predict unseen compound\n","def model_prediction(unseen_in_csv, featurizer, model, checkpoint):\n","  df=pd.read_csv(f'{unseen_in_csv}')\n","  # your csv file needs to have one column named 'smiles'\n","  loader_unseen = dc.data.data_loader.CSVLoader(tasks=[], feature_field = \"smiles\", featurizer = featurizer)\n","  # loader_unseen = dc.data.data_loader.CSVLoader(tasks=[], feature_field = \"smiles\", featurizer = DMPNN_featurizer)\n","  # loader_unseen = dc.data.data_loader.CSVLoader(tasks=[] , feature_field = \"smiles\", featurizer = GCN_featurizer)\n","  dataset_test= loader_unseen.create_dataset(f'{unseen_in_csv}')\n","  model.restore(f'{checkpoint}')\n","  predicted_halflife= model.predict(dataset_test)\n","  #exp_pred_te=np.exp(np.ravel(predicted_halflife))\n","  #te_pred_P= 60*np.array((exp_pred_te))\n","  output_df= pd.DataFrame()\n","  output_df['smiles']= df['smiles']\n","  output_df['predicted_halflife']= np.array(predicted_halflife)\n","  #output_df['predicted_halflife']= te_pred_P\n","  print(output_df)\n","  output_df.to_csv('prediction_result.cav')\n","\n","\n","\n","DMPNN_featurizer=dc.feat.DMPNNFeaturizer(features_generators=[\"rdkit_desc_normalized\"])\n","model_prediction('/content/test_smiles.csv', DMPNN_featurizer, model_dmpnn,'/content/checkpoint1.pt')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x4TXGXV1bExc","executionInfo":{"status":"ok","timestamp":1706823548220,"user_tz":-480,"elapsed":1595,"user":{"displayName":"鍾岳辰","userId":"02693086127626364792"}},"outputId":"82065f87-b991-4b54-b6fd-7ae13956076b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                               smiles  predicted_halflife\n","0   [2H]C([2H])(c1cc(Cl)ccc1NCc1ccc(S(C)(=O)=O)cc1...           -3.429336\n","1   CC(=O)N[C@@H]1CC[C@@]2(C)C(=CC[C@H]3[C@@H]4CC=...           -3.852561\n","2   COc1cncc(C2=CC[C@H]3[C@@H]4CC=C5C[C@H](NC(=O)C...           -4.256824\n","3   CC(=O)N[C@@H]1CC[C@@]2(C)C(=CC[C@H]3[C@@H]4CC=...           -4.391540\n","4   COc1cncc(C2=CC[C@H]3[C@@H]4CCC5C[C@@H](NC(C)=O...           -3.914470\n","5   CC(C)C(=O)N[C@H]1CC[C@@]2(C)C(CC[C@H]3[C@@H]4C...           -3.928624\n","6   CCNC(=O)N[C@@H]1CC[C@@]2(C)C(=CC[C@H]3[C@@H]4C...           -4.332470\n","7   C[C@]12CC[C@H]3[C@@H](CC=C4C[C@H](NC(=O)C5CCC5...           -4.213406\n","8   C[C@]12CC[C@H]3[C@@H](CCC4C[C@H](NC(=O)C5CC5)C...           -4.089286\n","9   CCCC(=O)N[C@@H]1CC[C@@]2(C)C(=CC[C@H]3[C@@H]4C...           -4.377962\n","10  C[C@]12CC[C@H]3[C@@H](CC=C4C[C@H](NC(=O)C5CC5)...           -4.212689\n","11  C[C@]12CC[C@H]3[C@@H](CCC4=CC(=O)NCC[C@@]43C)[...           -3.974460\n"]}]},{"cell_type":"markdown","source":["# 1.8 Plot functions"],"metadata":{"id":"juXjFLikuKT5"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from google.colab import files\n","def plot_r2(epoch, train_df, valid_df, test_df, filename, file_path):\n","  plt.xlabel(\"Epoch\")\n","  plt.ylabel(\"r2_score\")\n","  x = range(1,epoch+1)\n","  y1= train_df['train_r2']\n","  y2= valid_df['valid_r2']\n","  y3= test_df['test_r2']\n","  g = plt.plot(x, y1, color = \"saddlebrown\", label = \"train_r2\")\n","  g = plt.plot(x, y3, color = \"sandybrown\", label = \"valid_q2\")\n","  g = plt.plot(x, y2, color = \"red\", label = \"test_r2\")\n","  plt.ylim(bottom = 0, top = 1)\n","  plt.legend(loc = \"lower right\")\n","  plt.savefig(f\"{file_path}/{filename}_r2.png\")\n","  plt.show()"],"metadata":{"id":"EfDB258et9Pz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_rmse(epoch, train_df, valid_df, test_df, filename, file_path):\n","  plt.xlabel(\"Epoch\")\n","  plt.ylabel(\"RMSE\")\n","  x = range(1,epoch+1)\n","  y1= train_df['train_rmse']\n","  y2= valid_df['valid_rmse']\n","  y3= test_df['test_rmse']\n","  g = plt.plot(x, y1, color = \"saddlebrown\", label = \"train_RMSE\")\n","  g = plt.plot(x, y2, color = \"sandybrown\", label = \"valid_RMSE\")\n","  g = plt.plot(x, y3, color = \"red\", label = \"test_RMSE\")\n","  plt.ylim(bottom = 0, top = 1)\n","  plt.legend(loc = \"lower right\")\n","  plt.savefig(f\"{file_path}/{filename}_rmse.png\")\n","  plt.show()"],"metadata":{"id":"fefIU28buJY5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir /content/dmpnn/result_plots\n","\n","plot_r2(epoch=50, train_df= train_sus, valid_df=valid_sus, test_df=test_sus, filename='dmpnn_result_r2', file_path='/content/dmpnn/result_plots')\n","plot_rmse(epoch=50, train_df= train_sus, valid_df=valid_sus, test_df=test_sus, filename='dmpnn_result_rmse', file_path='/content/dmpnn/result_plots')"],"metadata":{"id":"e4j3g05Tvkj0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","\n","# Demonstration of plotting residual plot using observed and predicted values\n","df_r3=pd.read_csv('No_dataselection_DMPNN_testing_pred_vs_obsered.csv')\n","sns.residplot(df_r3, x=\"Observed(min)\", y=\"Prediction of testing-set(min)\", lowess=True, line_kws=dict(color='r'))"],"metadata":{"id":"awFYdiW6udUj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1.9 Classifcation results of trained model"],"metadata":{"id":"ADcFzNTeHrdi"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import matthews_corrcoef\n","import matplotlib.pyplot as plt\n","\n","def result_in_class(pred_result_file, observed_col, predict_col):\n","\n","  result= pd.read_csv(f'{pred_result_file}')\n","  ytest_O= np.array(result[f'{observed_col}'])\n","  ytest_P= np.array(result[f'{predict_col}'])\n","\n","  obs=[]\n","  pred=[]\n","\n","  for i in range(len(ytest_P)):\n","    #print(i)\n","    if float(ytest_P[i]) < 30.0:\n","      pred.append(0)\n","    if float(ytest_O[i]) < 30.0:\n","      obs.append(0)\n","    if 30.0 <= float(ytest_P[i]) <= 60.0:\n","      pred.append(1)\n","    if 30.0 <= float(ytest_O[i]) <= 60.0:\n","      obs.append(1)\n","    if float(ytest_P[i]) > 60.0:\n","      pred.append(2)\n","    if float(ytest_O[i]) > 60.0:\n","      obs.append(2)\n","    else:\n","      print('NULL values')\n","      continue\n","\n","  pred= np.array(pred)\n","  obs= np.array(obs)\n","\n","  plt.figure(figsize=(10,6))\n","  fx=sns.heatmap(confusion_matrix(obs, pred), annot=True, fmt=\".2f\",cmap=\"GnBu\")\n","  fx.set_title('Confusion Matrix \\n');\n","  fx.set_xlabel('\\n Predicted class\\n')\n","  fx.set_ylabel('Actual class\\n');\n","  fx.xaxis.set_ticklabels(['unstable','moderate','stable'])\n","  fx.yaxis.set_ticklabels(['unstable','moderate','stable'])\n","  plt.show()\n","  print('\\n')\n","  target_name= ['unstable','moderate','stable']\n","  print(classification_report(obs, pred, target_names= target_name))\n","  print('\\n')\n","  print('mcc: ', matthews_corrcoef(obs, pred))"],"metadata":{"id":"OcQjLxZGH1zF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_in_class('/content/deepchem_DMPNN_testing_result_record.csv', 'Observed(min)', 'Prediction of testing-set(min)')"],"metadata":{"id":"6Bm53sBSH79_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1.10 Plot molecules"],"metadata":{"id":"BACrNqtPu5ZH"}},{"cell_type":"code","source":["from rdkit import Chem\n","from rdkit.Chem import AllChem\n","from collections import defaultdict\n","from rdkit.Chem import rdFMCS\n","from rdkit.Chem import Draw\n","from rdkit.Chem.Draw import IPythonConsole\n","\n","#needed for show_mols\n","#more: http://rdkit.blogspot.com/2020/04/new-drawing-options-in-202003-release.html\n","from rdkit.Chem.Draw import rdMolDraw2D\n","from IPython.display import SVG\n","import cairosvg\n","import math\n","import os\n","\n","from rdkit import rdBase"],"metadata":{"id":"ZyOxNyVhu7TE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import math\n","import cairosvg\n","#this functon is designed to plot a group of molecules in defined number per row\n","def show_mols(mols, mols_per_row = 5, size=300, min_font_size=12, legends=[], file_name=''):\n","\n","  if legends and len(legends) < len(mols):\n","    print('legends is too short')\n","    return None\n","\n","  mols_per_row = min(len(mols), mols_per_row)\n","  rows = math.ceil(len(mols)/mols_per_row)\n","  d2d = rdMolDraw2D.MolDraw2DSVG(mols_per_row*size,rows*size,size,size)\n","  d2d.drawOptions().minFontSize = min_font_size\n","  if legends:\n","    d2d.DrawMolecules(mols, legends=legends)\n","  else:\n","    d2d.DrawMolecules(mols)\n","  d2d.FinishDrawing()\n","\n","  if file_name:\n","    with open('d2d.svg', 'w') as f:\n","      f.write(d2d.GetDrawingText())\n","      if 'pdf' in file_name:\n","        cairosvg.svg2pdf(url='d2d.svg', write_to=file_name)\n","      else:\n","        cairosvg.svg2png(url='d2d.svg', write_to=file_name)\n","      os.remove('d2d.svg')\n","\n","  return SVG(d2d.GetDrawingText())\n","\n","# mols_per_row and chunk_size must be matched\n","def divide_chunks(total_length, chunk_size):\n","  # looping till length l\n","  for i in range(0, len(total_length), chunk_size):\n","    yield total_length[i:i + chunk_size]\n"],"metadata":{"id":"6NTNO12IvEgc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_bg60= pd.read_csv('No_dataselection_biggerthan60.csv')\n","drawsmi= df_bg60['SMILES']\n","print(drawsmi)\n","mols = [Chem.MolFromSmiles(x) for x in drawsmi]\n","legends= [str(i) for i in range(len(drawsmi))]\n","#print(legends)\n","\n","n = 5\n","x = list(divide_chunks(mols, n))\n","y = list(divide_chunks(legends, n))\n","\n","file_path= '/content/dmpnn/result_plots'\n","\n","for chunck in range(len(x)):\n","  show_mols(mols= x[chunck], legends=y[chunck], file_name=f'{file_path}/{chunck}.png')"],"metadata":{"id":"Lwr1PHfvviIC"},"execution_count":null,"outputs":[]}]}