{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM2EOSABGoq7cOJ+oXwZ9cY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"L1PkSzuXJBZt"},"outputs":[],"source":["!pip install rdkit-pypi\n","!pip install graphviz\n","!pip install xgboost\n","!pip install optuna\n","!pip install padelpy\n","!wget https://github.com/dataprofessor/padel/raw/main/fingerprints_xml.zip\n","!unzip fingerprints_xml.zip"]},{"cell_type":"markdown","source":["# 5.1.1 Calculate the PaDEL descriptors"],"metadata":{"id":"8KkpbiznTzD2"}},{"cell_type":"code","source":["import glob\n","xml_files = glob.glob(\"*.xml\")\n","xml_files.sort()\n","\n","FP_list = ['AtomPairs2DCount',\n"," 'AtomPairs2D',\n"," 'EState',\n"," 'CDKextended',\n"," 'CDK',\n"," 'CDKgraphonly',\n"," 'KlekotaRothCount',\n"," 'KlekotaRoth',\n"," 'MACCS',\n"," 'PubChem',\n"," 'SubstructureCount',\n"," 'Substructure']\n","\n","fp = dict(zip(FP_list, xml_files))\n","\n"],"metadata":{"id":"m4vYLt-rKcl1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","df1 = pd.read_csv('/content/regression_equal_no_ion_5_smaller.csv')\n","df2 = pd.read_csv('/content/eli_duplcate_hf.csv')\n","d1= dict(zip(df1['SMILES'], df1['STANDARD_VALUE_LN']))\n","d2= dict(zip(df2['smiles'], [d1[smi] for smi in df2['smiles']]))\n","d3= dict(zip(df1['SMILES'], df1['CHEMBL_ID']))\n","d4= dict(zip(df2['smiles'], [d3[smi] for smi in df2['smiles']]))\n","\n","\n","df4= pd.DataFrame()\n","df4['half_life'], df4['SMILES'], df4['CHEML_ID'] = np.array([d1[smi] for smi in df2['smiles']]), df2['smiles'], np.array([d3[smi] for smi in df2['smiles']])\n","# save .smi file for padel descriptor\n","df4['SMILES'].to_csv('molecule.smi', sep='\\t', index=False, header=False)\n"],"metadata":{"id":"g75xzFVYSqBB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from padelpy import padeldescriptor\n","\n","fingerprints= ['EState', 'CDKextended', 'CDK', 'KlekotaRoth', 'MACCS', 'PubChem']\n","for fingerprint in fingerprints:\n","  fingerprint_output_file = ''.join([fingerprint,'.csv']) #PubChem.csv\n","  fingerprint_descriptortypes = fp[fingerprint]\n","  print(fingerprint_descriptortypes)\n","  padeldescriptor(  mol_dir='molecule.smi',\n","            d_file=fingerprint_output_file, #'PubChem.csv'\n","            descriptortypes= fingerprint_descriptortypes,\n","            detectaromaticity=True,\n","            standardizenitro=True,\n","            standardizetautomers=True,\n","            threads=8,\n","            removesalt=False,\n","            log=True,\n","            fingerprints=True )\n","\n","#add  SMILES and CHEML_ID columns to result csv files\n","for fp in fingerprints:\n","  descriptors = pd.read_csv(f'{fp}.csv')\n","  descriptors.insert(loc= 0, column = 'smiles', value = df4['SMILES'])\n","  descriptors.insert(loc= 0, column = 'Chembl_ID', value = df4['CHEML_ID'])\n","  print(descriptors)\n","  descriptors.to_csv(f'{fp}_FP_withID.csv')\n"],"metadata":{"id":"5RJHLYtiTELS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5.1.2 Calculate the RDKit descriptors"],"metadata":{"id":"BcwQFkGHUD2S"}},{"cell_type":"code","source":["# Ref: https://github.com/rdkit/benchmarking_platform/blob/master/scoring/fingerprint_lib.py\n","\n","from rdkit import Chem\n","from rdkit.Chem import MACCSkeys, AllChem\n","from rdkit.Avalon import pyAvalonTools as fpAvalon\n","from rdkit.Chem.AtomPairs import Pairs, Torsions\n","from rdkit.Chem.Fingerprints import FingerprintMols\n","from rdkit.Chem.ChemicalFeatures import BuildFeatureFactory\n","from rdkit.Chem import rdMolDescriptors\n","\n","# implemented fingerprints:\n","# ECFC0 (ecfc0), ECFP0 (ecfp0), MACCS (maccs),\n","# atom pairs (ap), atom pairs bit vector (apbv), topological torsions (tt)\n","# hashed atom pairs (hashap), hashed topological torsions (hashtt) --> with 1024 bits\n","# ECFP4 (ecfp4), ECFP6 (ecfp6), ECFC4 (ecfc4), ECFC6 (ecfc6) --> with 1024 bits\n","# FCFP4 (fcfp4), FCFP6 (fcfp6), FCFC4 (fcfc4), FCFC6 (fcfc6) --> with 1024 bits\n","# Avalon (avalon) --> with 1024 bits\n","# long Avalon (laval) --> with 16384 bits\n","# long ECFP4 (lecfp4), long ECFP6 (lecfp6), long FCFP4 (lfcfp4), long FCFP6 (lfcfp6) --> with 16384 bits\n","# RDKit with path length = 5 (rdk5), with path length = 6 (rdk6), with path length = 7 (rdk7)\n","# 2D pharmacophore (pharm) ?????????????\n","\n","nbits = 1024\n","longbits = 16384\n","\n","# dictionary\n","fpdict = {}\n","fpdict['ecfp0'] = lambda m: AllChem.GetMorganFingerprintAsBitVect(m, 0, nBits=nbits)\n","fpdict['ecfp2'] = lambda m: AllChem.GetMorganFingerprintAsBitVect(m, 1, nBits=nbits)\n","fpdict['ecfp4'] = lambda m: AllChem.GetMorganFingerprintAsBitVect(m, 2, nBits=nbits)\n","fpdict['ecfp6'] = lambda m: AllChem.GetMorganFingerprintAsBitVect(m, 3, nBits=nbits)\n","fpdict['ecfc0'] = lambda m: AllChem.GetMorganFingerprint(m, 0)\n","fpdict['ecfc2'] = lambda m: AllChem.GetMorganFingerprint(m, 1)\n","fpdict['ecfc4'] = lambda m: AllChem.GetMorganFingerprint(m, 2)\n","fpdict['ecfc6'] = lambda m: AllChem.GetMorganFingerprint(m, 3)\n","fpdict['fcfp2'] = lambda m: AllChem.GetMorganFingerprintAsBitVect(m, 1, useFeatures=True, nBits=nbits)\n","fpdict['fcfp4'] = lambda m: AllChem.GetMorganFingerprintAsBitVect(m, 2, useFeatures=True, nBits=nbits)\n","fpdict['fcfp6'] = lambda m: AllChem.GetMorganFingerprintAsBitVect(m, 3, useFeatures=True, nBits=nbits)\n","fpdict['fcfc2'] = lambda m: AllChem.GetMorganFingerprint(m, 1, useFeatures=True)\n","fpdict['fcfc4'] = lambda m: AllChem.GetMorganFingerprint(m, 2, useFeatures=True)\n","fpdict['fcfc6'] = lambda m: AllChem.GetMorganFingerprint(m, 3, useFeatures=True)\n","fpdict['lecfp4'] = lambda m: AllChem.GetMorganFingerprintAsBitVect(m, 2, nBits=longbits)\n","fpdict['lecfp6'] = lambda m: AllChem.GetMorganFingerprintAsBitVect(m, 3, nBits=longbits)\n","fpdict['lfcfp4'] = lambda m: AllChem.GetMorganFingerprintAsBitVect(m, 2, useFeatures=True, nBits=longbits)\n","fpdict['lfcfp6'] = lambda m: AllChem.GetMorganFingerprintAsBitVect(m, 3, useFeatures=True, nBits=longbits)\n","fpdict['maccs'] = lambda m: MACCSkeys.GenMACCSKeys(m)\n","fpdict['ap'] = lambda m: Pairs.GetAtomPairFingerprint(m)\n","fpdict['tt'] = lambda m: Torsions.GetTopologicalTorsionFingerprintAsIntVect(m)\n","fpdict['hashap'] = lambda m: rdMolDescriptors.GetHashedAtomPairFingerprintAsBitVect(m, nBits=nbits)\n","fpdict['hashtt'] = lambda m: rdMolDescriptors.GetHashedTopologicalTorsionFingerprintAsBitVect(m, nBits=nbits)\n","fpdict['avalon'] = lambda m: fpAvalon.GetAvalonFP(m, nbits)\n","fpdict['laval'] = lambda m: fpAvalon.GetAvalonFP(m, longbits)\n","fpdict['rdk5'] = lambda m: Chem.RDKFingerprint(m, maxPath=5, fpSize=nbits, nBitsPerHash=2)\n","fpdict['rdk6'] = lambda m: Chem.RDKFingerprint(m, maxPath=6, fpSize=nbits, nBitsPerHash=2)\n","fpdict['rdk7'] = lambda m: Chem.RDKFingerprint(m, maxPath=7, fpSize=nbits, nBitsPerHash=2)\n","\n","\n","def CalculateFP(fp_name, smiles):\n","    m = Chem.MolFromSmiles(smiles)\n","    if m is None:\n","        raise ValueError('SMILES cannot be converted to a RDKit molecules:', smiles)\n","\n","    return fpdict[fp_name](m)"],"metadata":{"id":"96mE_mGXLBjW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5.2 Select suitable fingerprint by KL divergence"],"metadata":{"id":"uBksFu1XbRtq"}},{"cell_type":"code","source":["import random\n","import os\n","\n","def set_seed(seed: int = 42) -> None:\n","  np.random.seed(seed)\n","  random.seed(seed)\n","  # Set a fixed value for the hash seed\n","  os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","  print(f\"Random seed set as {seed}\")\n","\n","def cv2arr(df):\n","  result=[]\n","  for i in range(len(df)):\n","    arr=np.array(df.iloc[i,1:], dtype=int)\n","    result.append(arr)\n","\n","  return result"],"metadata":{"id":"qvpsNbK5U1h4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fp1= pd.read_csv('/content/PubChem.csv')\n","pubchemfp=cv2arr(fp1)\n","\n","fp2= pd.read_csv('/content/CDK.csv')\n","cdk_fp=cv2arr(fp2)\n","\n","fp3= pd.read_csv('/content/CDKextended.csv')\n","cdkE_fp=cv2arr(fp3)\n","\n","fp4= pd.read_csv('/content/EState.csv')\n","Es_fp=cv2arr(fp4)\n","\n","fp5= pd.read_csv('/content/KlekotaRoth.csv')\n","kl_fp=cv2arr(fp5)\n","\n","fp6= pd.read_csv('/content/MACCS.csv')\n","macc_fp=cv2arr(fp6)"],"metadata":{"id":"mz-aEfcmb0cu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","#df2 = pd.read_csv('/content/eli_duplcate_hf.csv')\n","smi=df2['smiles']\n","\n","fcfp4=[]\n","fcfp6=[]\n","ecfp4=[]\n","ecfp6=[]\n","for i in smi:\n","  fcfp4.append(np.array(CalculateFP('fcfp4',i)))\n","  fcfp6.append(np.array(CalculateFP('fcfp6',i)))\n","  ecfp4.append(np.array(CalculateFP('ecfp4',i)))\n","  ecfp6.append(np.array(CalculateFP('ecfp6',i)))"],"metadata":{"id":"pPv8BeOCThSg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from sklearn.manifold import TSNE\n","\n","def plot_tsne(fp, color):\n","  estim= TSNE(metric='jaccard', init='random',  random_state=8)\n","  projection = estim.fit_transform(fp)\n","  # kl_divergence_ lower is better\n","  print('kl_divergence: ', estim.kl_divergence_)\n","  plt.scatter(*projection.T, marker=\".\", s=30, lw=0, alpha=0.7, c=color, edgecolor=\"k\")\n","  plt.show()\n","\n","for i in [cdk_fp, cdkE_fp, Es_fp, kl_fp, macc_fp, pubchemfp, fcfp4, fcfp6, ecfp4, ecfp6]:\n","  print(f'{i}')\n","  plot_tsne(np.array(i), 'b')"],"metadata":{"id":"SfYbtW8gaLNn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from scipy.spatial.distance import pdist, squareform\n","\n","def Calculate_tanimoto_similarity(fp:np.array):\n","  fingerprint = np.array(fp)\n","  # If attributes in arrays  are all binary, the Tanimoto simiarity reduces to the Jaccard simiarity,\n","  # In this case, fingeprints are arrays consisted of binary values\n","  jaccard_distance= pdist(fingerprint, 'jaccard')\n","  # get square matrix\n","  sq_jd= squareform(jaccard_distance)\n","  jsim= 1- sq_jd\n","\n","  return jsim"],"metadata":{"id":"UALk86ZNDptS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5.3 Random seed selection for ML methods"],"metadata":{"id":"p_rSkEkngIcg"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.svm import SVR\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","import xgboost as xgb\n","\n","df= pd.read_csv('/content/eli_duplcate_hf.csv')\n","\n","X=np.array(pubchemfp)\n","y=df['half_life']\n","\n","def svr_seed_select(start_point, end_point, points, X, y):\n","  svmr=[]\n","  intr=[]\n","  for i in np.random.randint(start_point,end_point, size=points):\n","    intr.append(i)\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state= i)\n","    svm= SVR(max_iter=-1)\n","    svm.fit(X_train,y_train)\n","    svm_p= svm.predict(X_val)\n","    svm_rmse= mean_squared_error(y_val, svm_p, squared=False)\n","    svmr.append(svm_rmse)\n","\n","  ids= np.argmin(np.array(svmr))\n","  print('best svr results: ', svmr[ids])\n","  print('best seed: ', intr[ids])\n","\n","  return intr[ids]\n","\n","\n","def rf_seed_select(start_point, end_point, points, X, y):\n","  rfr=[]\n","  intr=[]\n","  for i in np.random.randint(start_point,end_point, size=points):\n","    intr.append(i)\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state= i)\n","    rf= RandomForestRegressor(min_samples_split=0.05, n_jobs= -1)\n","    rf.fit(X_train,y_train)\n","    rf_p= rf.predict(X_val)\n","    rf_rmse= mean_squared_error(y_val, rf_p, squared=False)\n","    rfr.append(rf_rmse)\n","\n","  idr= np.argmin(np.array(rfr))\n","  print('best svr results: ', rfr[idr])\n","  print('best seed: ', intr[idr])\n","\n","  return intr[ids]\n","\n","def xgboost_seed_select(start_point, end_point, points, X, y):\n","  xgbr=[]\n","  intr=[]\n","  for i in np.random.randint(start_point,end_point, size=points):\n","    intr.append(i)\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state= i)\n","    reg = xgb.XGBRegressor()\n","    reg.fit(X_train,y_train)\n","    xgb_p= reg.predict(X_val)\n","    xgb_rmse= mean_squared_error(y_val, xgb_p, squared=False)\n","    xgbr.append(xgb_rmse)\n","\n","  idr= np.argmin(np.array(xgbr))\n","  print('best svr results: ', xgbr[idr])\n","  print('best seed: ', intr[idr])\n","\n","  return intr[ids]\n","\n","\n"],"metadata":{"id":"v7Pjt-HOUPWP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5.4.1 Optuna for hyperparameter optiminzation"],"metadata":{"id":"Xy-wNu_cfgTh"}},{"cell_type":"code","source":["import optuna\n","from sklearn.ensemble import RandomForestRegressor\n","\n","\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n","\n","clf1 = RandomForestRegressor()\n","\n","param_distributions = {\n","    'criterion': optuna.distributions.CategoricalDistribution(choices=('squared_error','absolute_error','friedman_mse','poisson')),\n","    \"n_estimators\": optuna.distributions.IntDistribution(10, 100, step=5),\n","    \"min_samples_split\": optuna.distributions.IntDistribution(2, 10),\n","    \"min_samples_leaf\": optuna.distributions.IntDistribution(2, 10),\n","    'max_features': optuna.distributions.CategoricalDistribution(choices=('sqrt','log2'))\n","\n","}\n","\n","optuna_search = optuna.integration.OptunaSearchCV(\n","    clf1, param_distributions, cv=5, n_trials=200, random_state=42, enable_pruning=False, n_jobs=-1, timeout=150, verbose=1, scoring='r2'\n",")\n","\n","optuna_search.fit(X, y)\n","\n","print(\"Best trial:\")\n","trial_rf = optuna_search.study_.best_trial\n","\n","print(\"  Value: \", trial_rf.value)\n","print(\"  Params: \")\n","for key, value in trial_rf.params.items():\n","    print(\"    {}: {}\".format(key, value))\n","\n","best_rf_para= trial_rf.params\n"],"metadata":{"id":"7vzPRTCchPP5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import optuna\n","import numpy as np\n","from sklearn.model_selection import KFold\n","from sklearn.svm import SVR\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","\n","\n","#X = np.array(ecfp6)\n","#y = df2['half_life']\n","\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n","\n","clf = SVR()\n","param = {\n","    'kernel': optuna.distributions.CategoricalDistribution(choices=('poly','sigmoid','rbf')),\n","    \"C\": optuna.distributions.FloatDistribution(1e0, 1e3, log=True),\n","    'epsilon': optuna.distributions.FloatDistribution(1e-3, 1e1, log=True),\n","    'degree': optuna.distributions.IntDistribution(3, 6),\n","    'gamma': optuna.distributions.CategoricalDistribution(choices=(1, 0.1, 0.01, 0.001, 0.0001)),\n","    'coef0': optuna.distributions.FloatDistribution(1e-2, 1e0, log=True),\n","\n","      }\n","\n","\n","#print(param)\n","optuna_search = optuna.integration.OptunaSearchCV(\n","    clf, param, cv=5, n_trials=200, random_state=42, enable_pruning=False, n_jobs=-1, timeout=100, verbose=1, scoring='r2'\n",")\n","\n","optuna_search.fit(X, y)\n","\n","print(\"Best trial:\")\n","trial_svr = optuna_search.study_.best_trial\n","\n","print(\"  Value: \", trial_svr.value)\n","print(\"  Params: \")\n","for key, value in trial_svr.params.items():\n","    print(\"    {}: {}\".format(key, value))\n","\n","best_svr_para= trial_svr.params"],"metadata":{"id":"5B0Euwa2hUZF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import xgboost as xgb\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n","\n","def objective(trial):\n","\n","  dtrain = xgb.DMatrix(X_train, label=y_train)\n","\n","  param = {\n","      \"verbosity\": 0,\n","      \"objective\": \"reg:squarederror\",\n","      \"eval_metric\": \"rmse\",\n","      \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]),\n","      \"lambda\": trial.suggest_float(\"lambda\", 1e-5, 1.0, log=True),\n","      \"alpha\": trial.suggest_float(\"alpha\", 1e-5, 1.0, log=True),\n","  }\n","\n","  if param[\"booster\"] == \"gbtree\" or param[\"booster\"] == \"dart\":\n","      param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 9)\n","      param[\"eta\"] = trial.suggest_float(\"eta\", 1e-5, 1.0, log=True)\n","      param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-5, 1.0, log=True)\n","      param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n","  if param[\"booster\"] == \"dart\":\n","      param[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n","      param[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n","      param[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-5, 1.0, log=True)\n","      param[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-5, 1.0, log=True)\n","\n","\n","  pruning_callback = optuna.integration.XGBoostPruningCallback(trial, \"test-rmse\")\n","  history = xgb.cv(param, dtrain, nfold=5, metrics='rmse', num_boost_round=10, seed=1348, callbacks=[pruning_callback])\n","  n_rmse = history[\"test-rmse-mean\"].values[-1]\n","\n","  return n_rmse\n","\n","\n","pruner = optuna.pruners.MedianPruner(n_warmup_steps=5)\n","study = optuna.create_study(pruner=pruner, direction=\"minimize\")\n","study.optimize(objective, n_trials=200)\n","print('Best hyperparameters:', study.best_params)\n","best_xgb_para= study.best_params\n","print('Best RMSE:', study.best_value)"],"metadata":{"id":"TktV8a64feWd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5.4.2 Gridsearch in case svm and RF running too long"],"metadata":{"id":"faMOO-bmhnN1"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import r2_score, mean_squared_error\n","\n","def ML_RF(X_train, y_train, X_val, y_val):\n","  param_grid_rf = {'n_estimators': [100,200,300,400],'min_samples_split':[0.05],'min_samples_leaf':[i for i in range(1,10)], 'max_features':[1,2,3,4,5], 'max_samples':[0.7,0.8,0.9], 'n_jobs':[-1] }\n","  grid_rf = GridSearchCV(RandomForestRegressor(),param_grid_rf, n_jobs=-1, refit=True, verbose=3, scoring='r2')\n","  grid_rf.fit(X_train,y_train)\n","  print(grid_rf.best_params_)\n","  print(grid_rf.best_score_)\n","  grid_predictions_rf = grid_rf.predict(X_val)\n","  print(mean_squared_error(y_val, grid_predictions_rf, squared=False))\n","  rmse_rf= mean_squared_error(y_val, grid_predictions_rf, squared=False)\n","\n","  return grid_rf.best_score_, rmse_rf, grid_rf.best_params_"],"metadata":{"id":"1boWPwZeiEd1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","from sklearn.svm import SVR\n","from sklearn.metrics import r2_score, mean_squared_error\n","\n","def ML_SVR(X_train, y_train, X_val, y_val):\n","  param_grid = {'C': [1,10,100,250,500], 'gamma': [0,0.1,0.05,0.01,0.005,0.001], 'coef0':[0,0.1,0.05,0.01,0.005,0.001], 'epsilon':[0.1,0.01,0.001], 'kernel': ['rbf', 'poly', 'sigmoid'] }\n","  grid = GridSearchCV(SVR(),param_grid, n_jobs=-1, refit=True, verbose=3, scoring='r2')\n","  grid.fit(X_train,y_train)\n","  print(grid.best_params_)\n","  print(grid.best_score_)\n","  grid_predictions = grid.predict(X_val)\n","  print(mean_squared_error(y_val, grid_predictions, squared=False))\n","  rmse= mean_squared_error(y_val, grid_predictions, squared=False)\n","\n","  return grid.best_score_, rmse, grid.best_params_"],"metadata":{"id":"rGerIVK7hmV6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5.5 Preparing dataset"],"metadata":{"id":"1Am2LJPkYFG3"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","\n","df= pd.read_csv('/content/eli_duplcate_hf.csv')\n","fp= pd.read_csv('/content/PubChem2.csv')\n","\n","pubchemfp=cv2arr(fp)\n","X=np.array(pubchemfp)\n","y = df['half_life']\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state= 112)\n","\n","key= df['smiles']\n","smi_dic= dict(zip(key, X))\n","\n","df2= pd.read_csv('/content/Qrm_MW_TPSA.csv')\n","df3= pd.read_csv('/content/chem_group_ana.csv')\n","\n","rmn3_smi= df3['smiles'][df3['n3_ring']==0]\n","rmn3_fp= np.array([smi_dic[i] for i in rmn3_smi])\n","rmn3_y= df3['half_life'][df3['n3_ring']==0]\n","\n","rmn7_smi= df3['smiles'][df3['n7_ring']==0]\n","rmn7_fp= np.array([smi_dic[i] for i in rmn7_smi])\n","rmn7_y= df3['half_life'][df3['n7_ring']==0]\n","\n","df4= pd.read_csv('/content/drop_by_q1q3.csv')\n","q1q3_fp= np.array([smi_dic[i] for i in df4['smiles']])\n","q1q3_y= df4['half_life']\n","\n","rmn3_train, rmn3_val, rmn3_y_train, rmn3_y_val = train_test_split(rmn3_fp, rmn3_y, test_size=0.1, random_state=112)\n","rmn7_train, rmn7_val, rmn7_y_train, rmn7_y_val = train_test_split(rmn7_fp, rmn7_y, test_size=0.1, random_state=112)\n","q1q3_train, q1q3_val, q1q3_y_train, q1q3_y_val = train_test_split(q1q3_fp, q1q3_y, test_size=0.1, random_state=112)\n","\n","\n","df5= pd.read_csv('/content/Qrm_MW_TPSA.csv')\n","MP_smi= df5['SMILES']\n","MP_fp= np.array([smi_dic[i] for i in MP_smi])\n","MP_y= df5['STANDARD_VALUE_LN']\n","MP_train, MP_val, MP_y_train, MP_y_val = train_test_split(MP_fp, MP_y, test_size=0.1, random_state=112)\n","\n","df6= pd.read_csv('/content/rm_mol.csv')\n","n3n7_smi= df6['smiles'][df6['n3n7']!=1]\n","n3n7_fp= np.array([smi_dic[i] for i in n3n7_smi])\n","n3n7_y= df6['half_life'][df6['n3n7']!=1]\n","n3n7_train, n3n7_val, n3n7_y_train, n3n7_y_val = train_test_split(n3n7_fp, n3n7_y, test_size=0.1, random_state=112)"],"metadata":{"id":"DNszGXxYYJd8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5.6 ML training and prediction"],"metadata":{"id":"8E4HAquwik3A"}},{"cell_type":"code","source":["from sklearn.svm import SVR\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import r2_score, mean_squared_error\n","\n","def ML_rf(best_rf_para, X_train, y_train, X_val, y_val):\n","  rf= RandomForestRegressor(**best_rf_para)\n","  #rf= RandomForestRegressor(min_samples_split=0.05, n_jobs= -1)\n","  rf.fit(X_train,y_train)\n","  rf_p= rf.predict(X_val)\n","\n","  print(r2_score(y_val, rf_p))\n","  print(mean_squared_error(y_val, rf_p, squared=False))\n","  rmse_sc= mean_squared_error(y_val, rf_p, squared=False)\n","  r2_sc= r2_score(y_val, rf_p)\n","\n","  return rmse_sc, r2_sc"],"metadata":{"id":"MCZmg6gym2Zc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.svm import SVR\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import r2_score, mean_squared_error\n","\n","def ML_svm(best_svr_para, X_train, y_train, X_val, y_val):\n","  svm= SVR(**best_svr_para)\n","  #svm= SVR(max_iter=-1)\n","  svm.fit(X_train,y_train)\n","  svm_p= svm.predict(X_val)\n","\n","  print(r2_score(y_val, svm_p))\n","  print(mean_squared_error(y_val, svm_p, squared=False))\n","  rmse_sc= mean_squared_error(y_val, svm_p, squared=False)\n","  r2_sc= r2_score(y_val, svm_p)\n","\n","  return rmse_sc, r2_sc"],"metadata":{"id":"eOvQPK-8mMBU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import xgboost as xgb\n","def ML_xgb(X_train, y_train, X_val, y_val):\n","  params = {\n","        \"objective\": \"reg:squarederror\",\n","        \"n_estimators\": 1000,\n","        \"verbosity\": 0,\n","        \"learning_rate\": 0.008759123511754415,\n","        \"max_depth\": 10,\n","        \"subsample\": 0.7630443989856173,\n","        \"colsample_bytree\": 0.6725557270413615,\n","        \"min_child_weight\": 4,\n","    }\n","\n","  model = xgb.XGBRegressor(**params)\n","  model.fit(X_train, y_train, verbose=False)\n","  predictions = model.predict(X_val)\n","  rmse_sc = mean_squared_error(y_val, predictions, squared=False)\n","  print(rmse_sc)\n","  r2_sc = r2_score(y_val, predictions)\n","  print(r2_sc)\n","\n","  return rmse_sc, r2_sc"],"metadata":{"id":"rQhj6OoogY8f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Here is the demonstration to perform ML analysis, use xgboost as example, rf and svm vise versa\n","rmse_sc, r2_sc= ML_xgb(X_train, y_train, X_val, y_val)\n","rmse_scn3, r2_sn3= ML_xgb(rmn3_train, rmn3_y_train, rmn3_val, rmn3_y_val)\n","rmse_scn7, r2n7_s= ML_xgb(rmn7_train, rmn7_y_train, rmn7_val, rmn7_y_val)\n","rmse_scq1q3, r2_sq1q3= ML_xgb(q1q3_train, q1q3_y_train, q1q3_val, q1q3_y_val)\n","print('n3n7')\n","ML_xgb(n3n7_train, n3n7_y_train, n3n7_val, n3n7_y_val)\n","print('MW_TPSA')\n","ML_xgb(MP_train, MP_y_train, MP_val, MP_y_val)"],"metadata":{"id":"5m4x3x3laSsE"},"execution_count":null,"outputs":[]}]}